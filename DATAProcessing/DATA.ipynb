{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we load, transform and save data, into workable formats for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 marginalpdbc files\n",
      "Found 365 precious files\n",
      "Processed 8760 rows from marginalpdbc files\n",
      "Processed 8760 rows from precious files\n",
      "Data has been processed and saved to '../TrainingData/trainingdata23.csv'\n",
      "   Year  Month   Day  Hour  Price1  Hour_Sin  Hour_Cos   Day_Sin   Day_Cos  \\\n",
      "0  2023    4.0  21.0   1.0  122.50  0.258819  0.965926 -0.897805 -0.440394   \n",
      "1  2023    4.0  21.0   2.0  112.39  0.500000  0.866025 -0.897805 -0.440394   \n",
      "2  2023    4.0  21.0   3.0  117.60  0.707107  0.707107 -0.897805 -0.440394   \n",
      "3  2023    4.0  21.0   4.0  119.84  0.866025  0.500000 -0.897805 -0.440394   \n",
      "4  2023    4.0  21.0   5.0  115.01  0.965926  0.258819 -0.897805 -0.440394   \n",
      "\n",
      "   Month_Sin  Month_Cos  Year_Scaled  Price2  \n",
      "0   0.866025       -0.5          0.6  118.92  \n",
      "1   0.866025       -0.5          0.6  106.69  \n",
      "2   0.866025       -0.5          0.6  113.43  \n",
      "3   0.866025       -0.5          0.6  113.48  \n",
      "4   0.866025       -0.5          0.6  108.63  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# File paths for marginalpdbc and precious_pibcic files\n",
    "marginalpdbc_files = glob.glob('../data_23/marginalpdbc*.csv')\n",
    "precious_files = glob.glob('../data_23/precios_pibci*.csv')\n",
    "\n",
    "print(f\"Found {len(marginalpdbc_files)} marginalpdbc files\")\n",
    "print(f\"Found {len(precious_files)} precious files\")\n",
    "\n",
    "# Function to encode time (day, month, hour) as sine and cosine\n",
    "def encode_time(value, max_value):\n",
    "    value_sin = np.sin(2 * np.pi * value / max_value)\n",
    "    value_cos = np.cos(2 * np.pi * value / max_value)\n",
    "    return value_sin, value_cos\n",
    "\n",
    "# Process marginalpdbc files\n",
    "marginal_data = []\n",
    "for file in marginalpdbc_files:\n",
    "    #print(f\"Processing marginalpdbc file: {file}\")\n",
    "    try:\n",
    "        data = pd.read_csv(file, delimiter=';', header=None, skiprows=1, usecols=range(6), encoding='latin1').iloc[:-1, :]\n",
    "        data.columns = ['Year', 'Month', 'Day', 'Hour', 'Price1', 'Unused']\n",
    "        data = data[['Year', 'Month', 'Day', 'Hour', 'Price1']].dropna()\n",
    "\n",
    "        # Convert columns to numeric\n",
    "        data['Year'] = pd.to_numeric(data['Year'], errors='coerce')\n",
    "        data['Month'] = pd.to_numeric(data['Month'], errors='coerce')\n",
    "        data['Day'] = pd.to_numeric(data['Day'], errors='coerce')\n",
    "        data['Hour'] = pd.to_numeric(data['Hour'], errors='coerce')\n",
    "        data['Price1'] = pd.to_numeric(data['Price1'], errors='coerce')\n",
    "        data = data.dropna(subset=['Year', 'Month', 'Day', 'Hour', 'Price1'])\n",
    "\n",
    "        # Encode time features\n",
    "        data['Hour_Sin'], data['Hour_Cos'] = zip(*data['Hour'].apply(lambda x: encode_time(x, 24)))\n",
    "        data['Day_Sin'], data['Day_Cos'] = zip(*data['Day'].apply(lambda x: encode_time(x, 31)))\n",
    "        data['Month_Sin'], data['Month_Cos'] = zip(*data['Month'].apply(lambda x: encode_time(x, 12)))\n",
    "\n",
    "        # Scale Year\n",
    "        data['Year_Scaled'] = (data['Year'] - 2018) * 0.1 + 0.1\n",
    "\n",
    "        marginal_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Combine all marginalpdbc data\n",
    "if marginal_data:\n",
    "    marginal_data = pd.concat(marginal_data, ignore_index=True)\n",
    "    print(f\"Processed {len(marginal_data)} rows from marginalpdbc files\")\n",
    "else:\n",
    "    print(\"No valid marginalpdbc data processed.\")\n",
    "\n",
    "# Process precious_pibcic files\n",
    "precious_data = []\n",
    "for file in precious_files:\n",
    "    #print(f\"Processing precious file: {file}\")\n",
    "    try:\n",
    "        data = pd.read_csv(file, delimiter=';', skiprows=2, encoding='latin1')  # Skip first two metadata rows\n",
    "        data = data.rename(columns=lambda x: x.strip())  # Normalize column names\n",
    "        data = data.rename(columns={\n",
    "            'Año': 'Year',\n",
    "            'Mes': 'Month',\n",
    "            'Día': 'Day',\n",
    "            'Hora': 'Hour',\n",
    "            'MedioES': 'Price2'\n",
    "        })[['Year', 'Month', 'Day', 'Hour', 'Price2']].dropna()\n",
    "\n",
    "        # Convert columns to numeric\n",
    "        data['Year'] = pd.to_numeric(data['Year'], errors='coerce')\n",
    "        data['Month'] = pd.to_numeric(data['Month'], errors='coerce')\n",
    "        data['Day'] = pd.to_numeric(data['Day'], errors='coerce')\n",
    "        data['Hour'] = pd.to_numeric(data['Hour'], errors='coerce')\n",
    "        data['Price2'] = pd.to_numeric(data['Price2'].str.replace(',', '.'), errors='coerce')  # Handle decimal commas\n",
    "        data = data.dropna(subset=['Year', 'Month', 'Day', 'Hour', 'Price2'])\n",
    "\n",
    "        precious_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Combine all precious_pibcic data\n",
    "if precious_data:\n",
    "    precious_data = pd.concat(precious_data, ignore_index=True)\n",
    "    print(f\"Processed {len(precious_data)} rows from precious files\")\n",
    "else:\n",
    "    print(\"No valid precious data processed.\")\n",
    "\n",
    "# Merge marginalpdbc and precious_pibcic data on Year, Month, Day, and Hour\n",
    "combined_data = pd.merge(\n",
    "    marginal_data,\n",
    "    precious_data,\n",
    "    on=['Year', 'Month', 'Day', 'Hour'],\n",
    "    how='inner',\n",
    "    suffixes=('_marginal', '_precious')\n",
    ")\n",
    "\n",
    "# Save to a CSV file\n",
    "output_file = '../TrainingData/trainingdata23.csv'\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"Data has been processed and saved to '{output_file}'\")\n",
    "\n",
    "# Debug: Preview the combined dataset\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we create the training data, from both the 2023 and 2024 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 700 marginalpdbc files\n",
      "Found 700 precious files\n",
      "Processed 16800 rows from marginalpdbc files\n",
      "Processed 16800 rows from precious files\n",
      "Data has been processed and saved to '../TrainingData/trainingdata_23_24.csv'\n",
      "   Year  Month   Day  Hour  Price1  Hour_Sin  Hour_Cos   Day_Sin   Day_Cos  \\\n",
      "0  2024    3.0  24.0   1.0    0.16  0.258819  0.965926 -0.988468  0.151428   \n",
      "1  2024    3.0  24.0   2.0    0.00  0.500000  0.866025 -0.988468  0.151428   \n",
      "2  2024    3.0  24.0   3.0    0.00  0.707107  0.707107 -0.988468  0.151428   \n",
      "3  2024    3.0  24.0   4.0    0.00  0.866025  0.500000 -0.988468  0.151428   \n",
      "4  2024    3.0  24.0   5.0    0.00  0.965926  0.258819 -0.988468  0.151428   \n",
      "\n",
      "   Month_Sin     Month_Cos  Year_Scaled  Price2  \n",
      "0        1.0  6.123234e-17          0.7    0.22  \n",
      "1        1.0  6.123234e-17          0.7    2.25  \n",
      "2        1.0  6.123234e-17          0.7   -1.39  \n",
      "3        1.0  6.123234e-17          0.7    0.90  \n",
      "4        1.0  6.123234e-17          0.7    1.79  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# File paths for marginalpdbc and precious_pibcic files\n",
    "marginalpdbc_files = glob.glob('../data_24/marginalpdbc*.*')  # Matches both .csv and .1 files\n",
    "precious_files = glob.glob('../data_24/precios_pibcic*.*')    # Matches both .csv and .1 files\n",
    "# Append data_23 file paths\n",
    "marginalpdbc_files += glob.glob('../data_23/marginalpdbc*.*')  # Add 2023 marginal files\n",
    "precious_files += glob.glob('../data_23/precios_pibcic*.*')    # Add 2023 precious files\n",
    "\n",
    "\n",
    "print(f\"Found {len(marginalpdbc_files)} marginalpdbc files\")\n",
    "print(f\"Found {len(precious_files)} precious files\")\n",
    "\n",
    "# Function to encode time (day, month, hour) as sine and cosine\n",
    "def encode_time(value, max_value):\n",
    "    value_sin = np.sin(2 * np.pi * value / max_value)\n",
    "    value_cos = np.cos(2 * np.pi * value / max_value)\n",
    "    return value_sin, value_cos\n",
    "\n",
    "# Process marginalpdbc files\n",
    "marginal_data = []\n",
    "for file in marginalpdbc_files:\n",
    "    try:\n",
    "        # Handle .1 files (same as .csv logic)\n",
    "        data = pd.read_csv(file, delimiter=';', header=None, skiprows=1, usecols=range(6), encoding='latin1').iloc[:-1, :]\n",
    "        data.columns = ['Year', 'Month', 'Day', 'Hour', 'Price1', 'Unused']\n",
    "        data = data[['Year', 'Month', 'Day', 'Hour', 'Price1']].dropna()\n",
    "\n",
    "        # Convert columns to numeric\n",
    "        data['Year'] = pd.to_numeric(data['Year'], errors='coerce')\n",
    "        data['Month'] = pd.to_numeric(data['Month'], errors='coerce')\n",
    "        data['Day'] = pd.to_numeric(data['Day'], errors='coerce')\n",
    "        data['Hour'] = pd.to_numeric(data['Hour'], errors='coerce')\n",
    "        data['Price1'] = pd.to_numeric(data['Price1'], errors='coerce')\n",
    "        data = data.dropna(subset=['Year', 'Month', 'Day', 'Hour', 'Price1'])\n",
    "\n",
    "        # Encode time features\n",
    "        data['Hour_Sin'], data['Hour_Cos'] = zip(*data['Hour'].apply(lambda x: encode_time(x, 24)))\n",
    "        data['Day_Sin'], data['Day_Cos'] = zip(*data['Day'].apply(lambda x: encode_time(x, 31)))\n",
    "        data['Month_Sin'], data['Month_Cos'] = zip(*data['Month'].apply(lambda x: encode_time(x, 12)))\n",
    "\n",
    "        # Scale Year\n",
    "        data['Year_Scaled'] = (data['Year'] - 2018) * 0.1 + 0.1\n",
    "\n",
    "        marginal_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Combine all marginalpdbc data\n",
    "if marginal_data:\n",
    "    marginal_data = pd.concat(marginal_data, ignore_index=True)\n",
    "    print(f\"Processed {len(marginal_data)} rows from marginalpdbc files\")\n",
    "else:\n",
    "    print(\"No valid marginalpdbc data processed.\")\n",
    "\n",
    "# Process precious_pibcic files\n",
    "precious_data = []\n",
    "for file in precious_files:\n",
    "    try:\n",
    "        # Handle .1 files (same as .csv logic)\n",
    "        data = pd.read_csv(file, delimiter=';', skiprows=2, encoding='latin1')  # Skip first two metadata rows\n",
    "        data = data.rename(columns=lambda x: x.strip())  # Normalize column names\n",
    "        data = data.rename(columns={\n",
    "            'Año': 'Year',\n",
    "            'Mes': 'Month',\n",
    "            'Día': 'Day',\n",
    "            'Hora': 'Hour',\n",
    "            'MedioES': 'Price2'\n",
    "        })[['Year', 'Month', 'Day', 'Hour', 'Price2']].dropna()\n",
    "\n",
    "        # Convert columns to numeric\n",
    "        data['Year'] = pd.to_numeric(data['Year'], errors='coerce')\n",
    "        data['Month'] = pd.to_numeric(data['Month'], errors='coerce')\n",
    "        data['Day'] = pd.to_numeric(data['Day'], errors='coerce')\n",
    "        data['Hour'] = pd.to_numeric(data['Hour'], errors='coerce')\n",
    "        data['Price2'] = pd.to_numeric(data['Price2'].str.replace(',', '.'), errors='coerce')  # Handle decimal commas\n",
    "        data = data.dropna(subset=['Year', 'Month', 'Day', 'Hour', 'Price2'])\n",
    "\n",
    "        precious_data.append(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Combine all precious_pibcic data\n",
    "if precious_data:\n",
    "    precious_data = pd.concat(precious_data, ignore_index=True)\n",
    "    print(f\"Processed {len(precious_data)} rows from precious files\")\n",
    "else:\n",
    "    print(\"No valid precious data processed.\")\n",
    "\n",
    "# Merge marginalpdbc and precious_pibcic data on Year, Month, Day, and Hour\n",
    "combined_data = pd.merge(\n",
    "    marginal_data,\n",
    "    precious_data,\n",
    "    on=['Year', 'Month', 'Day', 'Hour'],\n",
    "    how='inner',\n",
    "    suffixes=('_marginal', '_precious')\n",
    ")\n",
    "\n",
    "# Save to a CSV file\n",
    "output_file = '../TrainingData/trainingdata_23_24.csv'\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"Data has been processed and saved to '{output_file}'\")\n",
    "\n",
    "# Debug: Preview the combined dataset\n",
    "print(combined_data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
