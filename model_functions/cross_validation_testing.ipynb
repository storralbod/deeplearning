{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lstm_functions as lf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np\n",
    "import data_prep as dp\n",
    "\n",
    "import torch\n",
    "import model as m\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM_multivariate_input_multi_step_forecaster' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m cross_validation \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mcross_validation\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__globals__\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     37\u001b[0m cross_validation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm.LSTM_multivariate_input_multi_step_forecaster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m MockLSTMForecaster\n\u001b[0;32m---> 39\u001b[0m \u001b[43mcross_validation_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mcross_validation_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_validation_test\u001b[39m():\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprice_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mda_price_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgammas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgammas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/Documents/DTU/1st Semester/Deep Learning/Project/deeplearning/model_functions/lstm_functions.py:208\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(model_type, n_splits, price_data, gammas, model_params)\u001b[0m\n\u001b[1;32m    201\u001b[0m model \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mLSTM_multivariate_input_multi_step_forecaster(model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    202\u001b[0m                                                         model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    203\u001b[0m                                                         model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    204\u001b[0m                                                         model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    205\u001b[0m                                                         model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_horizon\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    206\u001b[0m                                                         model_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecast_horizon\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    207\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForecast shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mforecasts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, valid[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDA ES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSTM_multivariate_input_multi_step_forecaster' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "da_price_data = pd.read_csv(\"../models_santi/data_santi/data_da_23.csv\")\n",
    "\n",
    "# Cross-validation parameters\n",
    "n_splits = 5\n",
    "gammas = [0.1, 0.5, 1.0]\n",
    "model_params = {\n",
    "    \"input_size\": da_price_data.shape[1],\n",
    "    \"hidden_size\": 16,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.2,\n",
    "    \"past_horizon\": 10,\n",
    "    \"forecast_horizon\": 5,\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "class MockLSTMForecaster:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def forecast(self, length):\n",
    "        # Generate random forecasts\n",
    "        return np.random.uniform(50, 150, length)\n",
    "\n",
    "\n",
    "def cross_validation_test():\n",
    "    result = lf.cross_validation(\n",
    "        model_type=\"da\",\n",
    "        n_splits=n_splits,\n",
    "        price_data=da_price_data,\n",
    "        gammas=gammas,\n",
    "        model_params=model_params\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "# Replace LSTM class with the mock for testing\n",
    "cross_validation = lf.cross_validation.__globals__.copy()\n",
    "cross_validation['m.LSTM_multivariate_input_multi_step_forecaster'] = MockLSTMForecaster\n",
    "\n",
    "cross_validation_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLSTMForecaster:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def forecast(self, length):\n",
    "        # Generate random forecasts\n",
    "        return np.random.uniform(50, 150, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, past_horizon, forecast_horizon, target_col):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (pd.DataFrame): DataFrame containing the time series data.\n",
    "            past_horizon (int): Number of past timesteps to use as input.\n",
    "            forecast_horizon (int): Number of future timesteps to predict.\n",
    "            target_col (str): Column name for the target variable.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.past_horizon = past_horizon\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.past_horizon - self.forecast_horizon\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Input sequence\n",
    "        x = self.data.iloc[idx:idx + self.past_horizon].values\n",
    "        # Target sequence\n",
    "        y = self.data.iloc[idx + self.past_horizon:idx + self.past_horizon + self.forecast_horizon][self.target_col].values\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, epochs, lr, device):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs.squeeze(-1), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        valid_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_loader:\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(x_batch)\n",
    "                loss = criterion(outputs.squeeze(-1), y_batch)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Validation Loss: {valid_loss / len(valid_loader):.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def cross_validation_lstm(data, target_col, past_horizon, forecast_horizon, n_splits, model_params, training_params, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with the time series data.\n",
    "        target_col (str): Name of the target variable column.\n",
    "        past_horizon (int): Number of past timesteps for input.\n",
    "        forecast_horizon (int): Number of future timesteps to predict.\n",
    "        n_splits (int): Number of splits for TimeSeriesSplit.\n",
    "        model_params (dict): Parameters for the LSTM model.\n",
    "        training_params (dict): Parameters for training (epochs, learning rate, batch size).\n",
    "        device (str): 'cuda' or 'cpu'.\n",
    "    Returns:\n",
    "        pd.DataFrame: Cross-validation results.\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    results = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(tscv.split(data)):\n",
    "        train_data = data.iloc[train_index]\n",
    "        valid_data = data.iloc[valid_index]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = TimeSeriesDataset(train_data, past_horizon, forecast_horizon, target_col)\n",
    "        valid_dataset = TimeSeriesDataset(valid_data, past_horizon, forecast_horizon, target_col)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=training_params['batch_size'], shuffle=False)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=training_params['batch_size'], shuffle=False)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = m.LSTM_multivariate_input_multi_step_forecaster(\n",
    "            input_size=model_params['input_size'],\n",
    "            hidden_size=model_params['hidden_size'],\n",
    "            num_layers=model_params['num_layers'],\n",
    "            dropout=model_params['dropout'],\n",
    "            past_horizon=past_horizon,\n",
    "            forecast_horizon=forecast_horizon\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model = train_model(model, train_loader, valid_loader, training_params['epochs'], training_params['lr'], device)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        predictions, targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_pred = model(x_batch).squeeze(-1).cpu().numpy()\n",
    "                predictions.append(y_pred)\n",
    "                targets.append(y_batch.numpy())\n",
    "        \n",
    "        predictions = np.concatenate(predictions)\n",
    "        targets = np.concatenate(targets)\n",
    "\n",
    "        mape = mean_absolute_percentage_error(targets, predictions)\n",
    "        results.append({\"fold\": fold, \"MAPE\": mape})\n",
    "        print(f\"Fold {fold}, MAPE: {mape:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lstm(data, target_col, past_horizon, forecast_horizon, n_splits, param_grid, training_params, device):\n",
    "    from itertools import product\n",
    "    results = []\n",
    "\n",
    "    # Generate parameter combinations\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "\n",
    "    for params in param_combinations:\n",
    "        # Create parameter dictionary for this combination\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "\n",
    "        # Update model_params and training_params\n",
    "        model_params = {\n",
    "            \"input_size\": 13,  # Assuming all features are input\n",
    "            \"hidden_size\": param_dict[\"hidden_size\"],\n",
    "            \"num_layers\": param_dict[\"num_layers\"],\n",
    "            \"dropout\": param_dict[\"dropout\"]\n",
    "        }\n",
    "        training_params[\"lr\"] = param_dict[\"lr\"]\n",
    "\n",
    "        # Run cross-validation\n",
    "        cv_results = cross_validation_lstm(\n",
    "            data=data,\n",
    "            target_col=target_col,\n",
    "            past_horizon=past_horizon,\n",
    "            forecast_horizon=forecast_horizon,\n",
    "            n_splits=n_splits,\n",
    "            model_params=model_params,\n",
    "            training_params=training_params,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Compute average MAPE across folds\n",
    "        avg_mape = cv_results[\"MAPE\"].mean()\n",
    "\n",
    "        # Store the results with parameters\n",
    "        results.append({\"params\": param_dict, \"avg_mape\": avg_mape})\n",
    "        print(f\"Tested params: {param_dict}, Avg MAPE: {avg_mape:.4f}\")\n",
    "\n",
    "    # Return all results as a DataFrame\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 marginalpdbc files\n",
      "Found 365 precious files\n",
      "Processed 8760 rows from marginalpdbc files\n",
      "Processed 8760 rows from precious files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8862.1548, Validation Loss: 9564.8330\n",
      "Epoch 2/3, Train Loss: 8498.3294, Validation Loss: 9132.6260\n",
      "Epoch 3/3, Train Loss: 8086.8916, Validation Loss: 8648.1135\n",
      "Fold 0, MAPE: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9124.2887, Validation Loss: 7874.5540\n",
      "Epoch 2/3, Train Loss: 8184.4201, Validation Loss: 6891.2329\n",
      "Epoch 3/3, Train Loss: 7074.7526, Validation Loss: 5797.7572\n",
      "Fold 1, MAPE: 2367429191663616.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8504.1885, Validation Loss: 7819.7248\n",
      "Epoch 2/3, Train Loss: 7024.4301, Validation Loss: 6160.6853\n",
      "Epoch 3/3, Train Loss: 5384.0992, Validation Loss: 4493.6651\n",
      "Fold 2, MAPE: 198697216376832.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8243.0293, Validation Loss: 7655.0929\n",
      "Epoch 2/3, Train Loss: 6181.8237, Validation Loss: 5330.1822\n",
      "Epoch 3/3, Train Loss: 4063.6393, Validation Loss: 3328.0701\n",
      "Fold 3, MAPE: 572109575159808.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8081.7346, Validation Loss: 7165.9242\n",
      "Epoch 2/3, Train Loss: 5336.0459, Validation Loss: 4236.7096\n",
      "Epoch 3/3, Train Loss: 3042.8900, Validation Loss: 2356.1244\n",
      "Fold 4, MAPE: 371539266502656.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7915.5179, Validation Loss: 5572.1991\n",
      "Epoch 2/3, Train Loss: 4625.0918, Validation Loss: 2949.1881\n",
      "Epoch 3/3, Train Loss: 2381.4050, Validation Loss: 1993.2368\n",
      "Fold 5, MAPE: 1310313857155072.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7576.3679, Validation Loss: 5942.6594\n",
      "Epoch 2/3, Train Loss: 3903.1761, Validation Loss: 2548.6057\n",
      "Epoch 3/3, Train Loss: 2024.5293, Validation Loss: 1549.4877\n",
      "Fold 6, MAPE: 1.5075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7330.9959, Validation Loss: 5172.9961\n",
      "Epoch 2/3, Train Loss: 3341.0765, Validation Loss: 2224.8292\n",
      "Epoch 3/3, Train Loss: 1797.5390, Validation Loss: 1751.6447\n",
      "Fold 7, MAPE: 2965431446929408.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7019.3846, Validation Loss: 4708.0071\n",
      "Epoch 2/3, Train Loss: 2867.3399, Validation Loss: 1694.6797\n",
      "Epoch 3/3, Train Loss: 1710.0646, Validation Loss: 1331.6577\n",
      "Fold 8, MAPE: 3629418090070016.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6796.8031, Validation Loss: 4171.5631\n",
      "Epoch 2/3, Train Loss: 2514.2017, Validation Loss: 1645.4713\n",
      "Epoch 3/3, Train Loss: 1643.1541, Validation Loss: 1486.4683\n",
      "Fold 9, MAPE: 1054798333870080.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1246973692739584.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8931.2196, Validation Loss: 9715.5483\n",
      "Epoch 2/3, Train Loss: 8730.7976, Validation Loss: 9502.2613\n",
      "Epoch 3/3, Train Loss: 8530.6286, Validation Loss: 9274.4217\n",
      "Fold 0, MAPE: 0.9364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9324.1299, Validation Loss: 8279.5829\n",
      "Epoch 2/3, Train Loss: 8889.8290, Validation Loss: 7841.3636\n",
      "Epoch 3/3, Train Loss: 8397.5136, Validation Loss: 7355.6328\n",
      "Fold 1, MAPE: 1030220651954176.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8797.4084, Validation Loss: 8486.2934\n",
      "Epoch 2/3, Train Loss: 8097.6010, Validation Loss: 7711.2598\n",
      "Epoch 3/3, Train Loss: 7300.3467, Validation Loss: 6865.9224\n",
      "Fold 2, MAPE: 88245010432000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8684.7840, Validation Loss: 8648.4590\n",
      "Epoch 2/3, Train Loss: 7708.0306, Validation Loss: 7537.8156\n",
      "Epoch 3/3, Train Loss: 6595.9921, Validation Loss: 6343.9358\n",
      "Fold 3, MAPE: 247437226672128.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8666.7702, Validation Loss: 8541.2944\n",
      "Epoch 2/3, Train Loss: 7375.8741, Validation Loss: 7084.8519\n",
      "Epoch 3/3, Train Loss: 5961.0091, Validation Loss: 5585.0730\n",
      "Fold 4, MAPE: 164798348132352.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8645.8595, Validation Loss: 7015.0377\n",
      "Epoch 2/3, Train Loss: 7019.5014, Validation Loss: 5457.4140\n",
      "Epoch 3/3, Train Loss: 5276.2732, Validation Loss: 4000.4426\n",
      "Fold 5, MAPE: 631313820286976.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8406.5615, Validation Loss: 7955.4681\n",
      "Epoch 2/3, Train Loss: 6538.6259, Validation Loss: 5850.5206\n",
      "Epoch 3/3, Train Loss: 4630.7903, Validation Loss: 3939.1507\n",
      "Fold 6, MAPE: 1.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8347.5718, Validation Loss: 7334.8128\n",
      "Epoch 2/3, Train Loss: 6109.7433, Validation Loss: 5026.3234\n",
      "Epoch 3/3, Train Loss: 3978.3823, Validation Loss: 3207.2828\n",
      "Fold 7, MAPE: 1749654786015232.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8203.3757, Validation Loss: 7364.9172\n",
      "Epoch 2/3, Train Loss: 5694.9184, Validation Loss: 4631.2061\n",
      "Epoch 3/3, Train Loss: 3471.5068, Validation Loss: 2643.9307\n",
      "Fold 8, MAPE: 2353268684488704.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8126.7019, Validation Loss: 6980.8381\n",
      "Epoch 2/3, Train Loss: 5345.1935, Validation Loss: 4121.2126\n",
      "Epoch 3/3, Train Loss: 3060.1664, Validation Loss: 2313.6329\n",
      "Fold 9, MAPE: 742976527532032.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 700791560077312.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8870.2845, Validation Loss: 9562.8953\n",
      "Epoch 2/3, Train Loss: 8503.4185, Validation Loss: 9132.7199\n",
      "Epoch 3/3, Train Loss: 8089.7340, Validation Loss: 8644.4017\n",
      "Fold 0, MAPE: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9123.4176, Validation Loss: 7851.1215\n",
      "Epoch 2/3, Train Loss: 8158.7933, Validation Loss: 6862.3774\n",
      "Epoch 3/3, Train Loss: 7046.0124, Validation Loss: 5787.0548\n",
      "Fold 1, MAPE: 2373405638656000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8559.9595, Validation Loss: 7870.7579\n",
      "Epoch 2/3, Train Loss: 7064.4135, Validation Loss: 6181.5839\n",
      "Epoch 3/3, Train Loss: 5397.3634, Validation Loss: 4496.7056\n",
      "Fold 2, MAPE: 198538839457792.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8194.4566, Validation Loss: 7548.5685\n",
      "Epoch 2/3, Train Loss: 6056.0275, Validation Loss: 5189.2475\n",
      "Epoch 3/3, Train Loss: 3973.9506, Validation Loss: 3247.7730\n",
      "Fold 3, MAPE: 583660822593536.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8082.5552, Validation Loss: 7171.2091\n",
      "Epoch 2/3, Train Loss: 5362.5544, Validation Loss: 4281.6981\n",
      "Epoch 3/3, Train Loss: 3085.4333, Validation Loss: 2397.3132\n",
      "Fold 4, MAPE: 367475925450752.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7897.6707, Validation Loss: 5561.9385\n",
      "Epoch 2/3, Train Loss: 4630.9132, Validation Loss: 2961.3485\n",
      "Epoch 3/3, Train Loss: 2399.2273, Validation Loss: 1998.4266\n",
      "Fold 5, MAPE: 1304715904155648.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7508.5622, Validation Loss: 5857.7151\n",
      "Epoch 2/3, Train Loss: 3861.0133, Validation Loss: 2536.5665\n",
      "Epoch 3/3, Train Loss: 2033.2309, Validation Loss: 1554.4862\n",
      "Fold 6, MAPE: 1.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7300.3997, Validation Loss: 5124.1397\n",
      "Epoch 2/3, Train Loss: 3316.0637, Validation Loss: 2217.2423\n",
      "Epoch 3/3, Train Loss: 1812.6498, Validation Loss: 1750.5770\n",
      "Fold 7, MAPE: 2963198063935488.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7039.5082, Validation Loss: 4743.8912\n",
      "Epoch 2/3, Train Loss: 2905.7799, Validation Loss: 1712.9291\n",
      "Epoch 3/3, Train Loss: 1721.7004, Validation Loss: 1335.5819\n",
      "Fold 8, MAPE: 3617165622116352.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6745.2584, Validation Loss: 4085.0480\n",
      "Epoch 2/3, Train Loss: 2473.8177, Validation Loss: 1630.8333\n",
      "Epoch 3/3, Train Loss: 1651.3768, Validation Loss: 1486.3728\n",
      "Fold 9, MAPE: 1054941678403584.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1246310254510080.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8953.8461, Validation Loss: 9736.8583\n",
      "Epoch 2/3, Train Loss: 8753.5194, Validation Loss: 9520.7852\n",
      "Epoch 3/3, Train Loss: 8552.7328, Validation Loss: 9293.5121\n",
      "Fold 0, MAPE: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9328.5863, Validation Loss: 8262.0565\n",
      "Epoch 2/3, Train Loss: 8869.4176, Validation Loss: 7810.9588\n",
      "Epoch 3/3, Train Loss: 8363.9728, Validation Loss: 7315.1339\n",
      "Fold 1, MAPE: 1067782892421120.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8859.3291, Validation Loss: 8546.2597\n",
      "Epoch 2/3, Train Loss: 8155.8337, Validation Loss: 7762.3234\n",
      "Epoch 3/3, Train Loss: 7345.1307, Validation Loss: 6900.3372\n",
      "Fold 2, MAPE: 86832721166336.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8699.5357, Validation Loss: 8647.4378\n",
      "Epoch 2/3, Train Loss: 7707.8712, Validation Loss: 7527.5105\n",
      "Epoch 3/3, Train Loss: 6582.3951, Validation Loss: 6318.7610\n",
      "Fold 3, MAPE: 249623516020736.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8696.1496, Validation Loss: 8562.3669\n",
      "Epoch 2/3, Train Loss: 7391.1863, Validation Loss: 7079.5699\n",
      "Epoch 3/3, Train Loss: 5939.6874, Validation Loss: 5544.1829\n",
      "Fold 4, MAPE: 166720044007424.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8654.7465, Validation Loss: 7036.3063\n",
      "Epoch 2/3, Train Loss: 7074.6154, Validation Loss: 5525.6053\n",
      "Epoch 3/3, Train Loss: 5376.3994, Validation Loss: 4084.8990\n",
      "Fold 5, MAPE: 614653642145792.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8409.6039, Validation Loss: 7956.1752\n",
      "Epoch 2/3, Train Loss: 6518.2834, Validation Loss: 5803.7766\n",
      "Epoch 3/3, Train Loss: 4579.5709, Validation Loss: 3879.5161\n",
      "Fold 6, MAPE: 1.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8359.8366, Validation Loss: 7352.8359\n",
      "Epoch 2/3, Train Loss: 6153.8556, Validation Loss: 5085.0832\n",
      "Epoch 3/3, Train Loss: 4045.3528, Validation Loss: 3263.2348\n",
      "Fold 7, MAPE: 1727142178062336.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8224.6171, Validation Loss: 7385.7338\n",
      "Epoch 2/3, Train Loss: 5728.3582, Validation Loss: 4662.8840\n",
      "Epoch 3/3, Train Loss: 3504.1433, Validation Loss: 2671.6924\n",
      "Fold 8, MAPE: 2337401733120000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8089.9008, Validation Loss: 6901.9280\n",
      "Epoch 2/3, Train Loss: 5260.1109, Validation Loss: 4043.6460\n",
      "Epoch 3/3, Train Loss: 3013.4393, Validation Loss: 2280.3295\n",
      "Fold 9, MAPE: 749913168150528.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 700006990348288.0000\n",
      "Epoch 1/3, Train Loss: 8850.0472, Validation Loss: 9537.1986\n",
      "Epoch 2/3, Train Loss: 8472.2399, Validation Loss: 9097.3900\n",
      "Epoch 3/3, Train Loss: 8046.7263, Validation Loss: 8598.7935\n",
      "Fold 0, MAPE: 0.9029\n",
      "Epoch 1/3, Train Loss: 9085.2064, Validation Loss: 7817.0824\n",
      "Epoch 2/3, Train Loss: 8113.2345, Validation Loss: 6816.0900\n",
      "Epoch 3/3, Train Loss: 6992.0944, Validation Loss: 5731.3010\n",
      "Fold 1, MAPE: 2426104887377920.0000\n",
      "Epoch 1/3, Train Loss: 8507.5061, Validation Loss: 7825.4389\n",
      "Epoch 2/3, Train Loss: 7015.8926, Validation Loss: 6134.8074\n",
      "Epoch 3/3, Train Loss: 5347.4527, Validation Loss: 4447.6588\n",
      "Fold 2, MAPE: 201228478840832.0000\n",
      "Epoch 1/3, Train Loss: 8247.9687, Validation Loss: 7644.5470\n",
      "Epoch 2/3, Train Loss: 6156.8718, Validation Loss: 5306.8442\n",
      "Epoch 3/3, Train Loss: 4058.2013, Validation Loss: 3329.0779\n",
      "Fold 3, MAPE: 571991866212352.0000\n",
      "Epoch 1/3, Train Loss: 8072.8339, Validation Loss: 7158.7975\n",
      "Epoch 2/3, Train Loss: 5322.5077, Validation Loss: 4223.0367\n",
      "Epoch 3/3, Train Loss: 3027.8085, Validation Loss: 2350.2721\n",
      "Fold 4, MAPE: 372125361766400.0000\n",
      "Epoch 1/3, Train Loss: 7955.8426, Validation Loss: 5609.4296\n",
      "Epoch 2/3, Train Loss: 4649.4123, Validation Loss: 2957.1862\n",
      "Epoch 3/3, Train Loss: 2381.1865, Validation Loss: 1991.0342\n",
      "Fold 5, MAPE: 1312721320542208.0000\n",
      "Epoch 1/3, Train Loss: 7560.9251, Validation Loss: 5962.9883\n",
      "Epoch 2/3, Train Loss: 3945.4840, Validation Loss: 2589.1384\n",
      "Epoch 3/3, Train Loss: 2042.4480, Validation Loss: 1559.6264\n",
      "Fold 6, MAPE: 1.5021\n",
      "Epoch 1/3, Train Loss: 7295.3427, Validation Loss: 5129.6354\n",
      "Epoch 2/3, Train Loss: 3311.6114, Validation Loss: 2213.2356\n",
      "Epoch 3/3, Train Loss: 1795.3294, Validation Loss: 1749.8378\n",
      "Fold 7, MAPE: 2967788847104000.0000\n",
      "Epoch 1/3, Train Loss: 6978.6430, Validation Loss: 4647.6204\n",
      "Epoch 2/3, Train Loss: 2827.9827, Validation Loss: 1671.8922\n",
      "Epoch 3/3, Train Loss: 1701.5067, Validation Loss: 1330.7236\n",
      "Fold 8, MAPE: 3632558784905216.0000\n",
      "Epoch 1/3, Train Loss: 6749.9689, Validation Loss: 4109.5927\n",
      "Epoch 2/3, Train Loss: 2476.0814, Validation Loss: 1631.3680\n",
      "Epoch 3/3, Train Loss: 1643.1987, Validation Loss: 1485.6431\n",
      "Fold 9, MAPE: 1056443105017856.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1254096224911360.0000\n",
      "Epoch 1/3, Train Loss: 8930.0340, Validation Loss: 9713.0849\n",
      "Epoch 2/3, Train Loss: 8728.1321, Validation Loss: 9501.7566\n",
      "Epoch 3/3, Train Loss: 8528.1505, Validation Loss: 9272.0544\n",
      "Fold 0, MAPE: 0.9361\n",
      "Epoch 1/3, Train Loss: 9293.7327, Validation Loss: 8241.8356\n",
      "Epoch 2/3, Train Loss: 8849.2169, Validation Loss: 7799.2494\n",
      "Epoch 3/3, Train Loss: 8351.9010, Validation Loss: 7309.9030\n",
      "Fold 1, MAPE: 1069145470795776.0000\n",
      "Epoch 1/3, Train Loss: 8824.9942, Validation Loss: 8519.3006\n",
      "Epoch 2/3, Train Loss: 8137.3090, Validation Loss: 7760.8768\n",
      "Epoch 3/3, Train Loss: 7350.7249, Validation Loss: 6916.7963\n",
      "Fold 2, MAPE: 86180532060160.0000\n",
      "Epoch 1/3, Train Loss: 8630.0856, Validation Loss: 8586.1240\n",
      "Epoch 2/3, Train Loss: 7658.6753, Validation Loss: 7496.9871\n",
      "Epoch 3/3, Train Loss: 6561.0302, Validation Loss: 6318.2597\n",
      "Fold 3, MAPE: 249614858977280.0000\n",
      "Epoch 1/3, Train Loss: 8663.8783, Validation Loss: 8537.4678\n",
      "Epoch 2/3, Train Loss: 7364.7899, Validation Loss: 7060.7727\n",
      "Epoch 3/3, Train Loss: 5925.9417, Validation Loss: 5538.9530\n",
      "Fold 4, MAPE: 166954069393408.0000\n",
      "Epoch 1/3, Train Loss: 8629.4038, Validation Loss: 6991.0889\n",
      "Epoch 2/3, Train Loss: 6991.0628, Validation Loss: 5432.9497\n",
      "Epoch 3/3, Train Loss: 5255.4056, Validation Loss: 3981.0262\n",
      "Fold 5, MAPE: 635082922524672.0000\n",
      "Epoch 1/3, Train Loss: 8411.8177, Validation Loss: 7958.8222\n",
      "Epoch 2/3, Train Loss: 6526.0652, Validation Loss: 5829.8579\n",
      "Epoch 3/3, Train Loss: 4606.4854, Validation Loss: 3904.8158\n",
      "Fold 6, MAPE: 1.1069\n",
      "Epoch 1/3, Train Loss: 8384.5167, Validation Loss: 7390.5799\n",
      "Epoch 2/3, Train Loss: 6147.1439, Validation Loss: 5046.1573\n",
      "Epoch 3/3, Train Loss: 3987.3747, Validation Loss: 3206.6457\n",
      "Fold 7, MAPE: 1751045818548224.0000\n",
      "Epoch 1/3, Train Loss: 8195.9493, Validation Loss: 7351.6584\n",
      "Epoch 2/3, Train Loss: 5676.1097, Validation Loss: 4613.9048\n",
      "Epoch 3/3, Train Loss: 3459.7833, Validation Loss: 2630.5606\n",
      "Fold 8, MAPE: 2361178403635200.0000\n",
      "Epoch 1/3, Train Loss: 8097.2299, Validation Loss: 6915.5601\n",
      "Epoch 2/3, Train Loss: 5269.7041, Validation Loss: 4046.4629\n",
      "Epoch 3/3, Train Loss: 3003.6016, Validation Loss: 2277.0310\n",
      "Fold 9, MAPE: 750585464750080.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 706978661793792.0000\n",
      "Epoch 1/3, Train Loss: 8902.0775, Validation Loss: 9596.6153\n",
      "Epoch 2/3, Train Loss: 8528.3806, Validation Loss: 9146.3336\n",
      "Epoch 3/3, Train Loss: 8092.1404, Validation Loss: 8639.0304\n",
      "Fold 0, MAPE: 0.9047\n",
      "Epoch 1/3, Train Loss: 9107.7693, Validation Loss: 7840.8535\n",
      "Epoch 2/3, Train Loss: 8146.7471, Validation Loss: 6847.6775\n",
      "Epoch 3/3, Train Loss: 7034.0516, Validation Loss: 5764.1491\n",
      "Fold 1, MAPE: 2395937842397184.0000\n",
      "Epoch 1/3, Train Loss: 8503.0485, Validation Loss: 7800.9499\n",
      "Epoch 2/3, Train Loss: 6996.6497, Validation Loss: 6120.9793\n",
      "Epoch 3/3, Train Loss: 5347.4232, Validation Loss: 4453.3447\n",
      "Fold 2, MAPE: 200884478803968.0000\n",
      "Epoch 1/3, Train Loss: 8205.7367, Validation Loss: 7588.5226\n",
      "Epoch 2/3, Train Loss: 6101.1268, Validation Loss: 5234.1473\n",
      "Epoch 3/3, Train Loss: 4001.3650, Validation Loss: 3266.7776\n",
      "Fold 3, MAPE: 580899628384256.0000\n",
      "Epoch 1/3, Train Loss: 8131.9867, Validation Loss: 7237.1733\n",
      "Epoch 2/3, Train Loss: 5403.3270, Validation Loss: 4291.5731\n",
      "Epoch 3/3, Train Loss: 3086.6195, Validation Loss: 2388.6328\n",
      "Fold 4, MAPE: 368314584924160.0000\n",
      "Epoch 1/3, Train Loss: 7955.0075, Validation Loss: 5606.5690\n",
      "Epoch 2/3, Train Loss: 4671.2809, Validation Loss: 2977.6248\n",
      "Epoch 3/3, Train Loss: 2415.0321, Validation Loss: 1997.8451\n",
      "Fold 5, MAPE: 1305070507393024.0000\n",
      "Epoch 1/3, Train Loss: 7539.5145, Validation Loss: 5937.5593\n",
      "Epoch 2/3, Train Loss: 3933.9081, Validation Loss: 2596.9161\n",
      "Epoch 3/3, Train Loss: 2060.4000, Validation Loss: 1562.3536\n",
      "Fold 6, MAPE: 1.5008\n",
      "Epoch 1/3, Train Loss: 7294.8670, Validation Loss: 5110.4670\n",
      "Epoch 2/3, Train Loss: 3308.6883, Validation Loss: 2216.9148\n",
      "Epoch 3/3, Train Loss: 1805.8897, Validation Loss: 1751.6516\n",
      "Fold 7, MAPE: 2965000339587072.0000\n",
      "Epoch 1/3, Train Loss: 7019.1989, Validation Loss: 4700.4402\n",
      "Epoch 2/3, Train Loss: 2866.5541, Validation Loss: 1693.9623\n",
      "Epoch 3/3, Train Loss: 1723.5636, Validation Loss: 1333.5914\n",
      "Fold 8, MAPE: 3623204614569984.0000\n",
      "Epoch 1/3, Train Loss: 6800.6511, Validation Loss: 4166.9072\n",
      "Epoch 2/3, Train Loss: 2515.3696, Validation Loss: 1641.8300\n",
      "Epoch 3/3, Train Loss: 1652.5189, Validation Loss: 1486.7983\n",
      "Fold 9, MAPE: 1054092684165120.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1249340353937408.0000\n",
      "Epoch 1/3, Train Loss: 8954.1790, Validation Loss: 9743.7262\n",
      "Epoch 2/3, Train Loss: 8757.7100, Validation Loss: 9531.8417\n",
      "Epoch 3/3, Train Loss: 8559.2705, Validation Loss: 9302.5711\n",
      "Fold 0, MAPE: 0.9380\n",
      "Epoch 1/3, Train Loss: 9292.1606, Validation Loss: 8225.5388\n",
      "Epoch 2/3, Train Loss: 8833.1436, Validation Loss: 7773.7517\n",
      "Epoch 3/3, Train Loss: 8328.7064, Validation Loss: 7280.6440\n",
      "Fold 1, MAPE: 1092085964865536.0000\n",
      "Epoch 1/3, Train Loss: 8855.6122, Validation Loss: 8541.8948\n",
      "Epoch 2/3, Train Loss: 8150.4812, Validation Loss: 7766.7420\n",
      "Epoch 3/3, Train Loss: 7359.6995, Validation Loss: 6926.2762\n",
      "Fold 2, MAPE: 85781569863680.0000\n",
      "Epoch 1/3, Train Loss: 8633.9159, Validation Loss: 8572.6261\n",
      "Epoch 2/3, Train Loss: 7639.9154, Validation Loss: 7462.6570\n",
      "Epoch 3/3, Train Loss: 6528.3933, Validation Loss: 6278.6642\n",
      "Fold 3, MAPE: 253101533560832.0000\n",
      "Epoch 1/3, Train Loss: 8690.9423, Validation Loss: 8557.3253\n",
      "Epoch 2/3, Train Loss: 7387.1829, Validation Loss: 7082.2134\n",
      "Epoch 3/3, Train Loss: 5949.3692, Validation Loss: 5563.4738\n",
      "Fold 4, MAPE: 165819241725952.0000\n",
      "Epoch 1/3, Train Loss: 8662.9285, Validation Loss: 7025.2667\n",
      "Epoch 2/3, Train Loss: 7043.9947, Validation Loss: 5480.1530\n",
      "Epoch 3/3, Train Loss: 5297.4922, Validation Loss: 4008.2636\n",
      "Fold 5, MAPE: 629730990620672.0000\n",
      "Epoch 1/3, Train Loss: 8411.1252, Validation Loss: 7969.2225\n",
      "Epoch 2/3, Train Loss: 6559.3115, Validation Loss: 5879.6323\n",
      "Epoch 3/3, Train Loss: 4661.4762, Validation Loss: 3969.4839\n",
      "Fold 6, MAPE: 1.1016\n",
      "Epoch 1/3, Train Loss: 8351.9824, Validation Loss: 7338.2502\n",
      "Epoch 2/3, Train Loss: 6130.3153, Validation Loss: 5062.0258\n",
      "Epoch 3/3, Train Loss: 4024.5392, Validation Loss: 3248.7498\n",
      "Fold 7, MAPE: 1734591664619520.0000\n",
      "Epoch 1/3, Train Loss: 8214.9797, Validation Loss: 7383.3994\n",
      "Epoch 2/3, Train Loss: 5721.9136, Validation Loss: 4664.5801\n",
      "Epoch 3/3, Train Loss: 3502.7853, Validation Loss: 2663.5568\n",
      "Fold 8, MAPE: 2341873867816960.0000\n",
      "Epoch 1/3, Train Loss: 8093.6975, Validation Loss: 6912.0295\n",
      "Epoch 2/3, Train Loss: 5275.0079, Validation Loss: 4043.3970\n",
      "Epoch 3/3, Train Loss: 3002.3511, Validation Loss: 2271.2040\n",
      "Fold 9, MAPE: 751859258097664.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 705484415827968.0000\n",
      "Epoch 1/3, Train Loss: 8841.0869, Validation Loss: 9521.7105\n",
      "Epoch 2/3, Train Loss: 8456.3752, Validation Loss: 9076.7128\n",
      "Epoch 3/3, Train Loss: 8029.7204, Validation Loss: 8575.1349\n",
      "Fold 0, MAPE: 0.9018\n",
      "Epoch 1/3, Train Loss: 9124.8742, Validation Loss: 7877.9332\n",
      "Epoch 2/3, Train Loss: 8193.9449, Validation Loss: 6909.7981\n",
      "Epoch 3/3, Train Loss: 7104.0552, Validation Loss: 5846.5002\n",
      "Fold 1, MAPE: 2323658106208256.0000\n",
      "Epoch 1/3, Train Loss: 8506.4943, Validation Loss: 7818.8819\n",
      "Epoch 2/3, Train Loss: 7010.7915, Validation Loss: 6136.1304\n",
      "Epoch 3/3, Train Loss: 5353.2882, Validation Loss: 4449.8128\n",
      "Fold 2, MAPE: 201115551399936.0000\n",
      "Epoch 1/3, Train Loss: 8209.7582, Validation Loss: 7582.0381\n",
      "Epoch 2/3, Train Loss: 6083.2336, Validation Loss: 5209.8888\n",
      "Epoch 3/3, Train Loss: 3970.2023, Validation Loss: 3240.1716\n",
      "Fold 3, MAPE: 584742013501440.0000\n",
      "Epoch 1/3, Train Loss: 8120.4083, Validation Loss: 7233.5256\n",
      "Epoch 2/3, Train Loss: 5402.5000, Validation Loss: 4304.3110\n",
      "Epoch 3/3, Train Loss: 3086.6508, Validation Loss: 2390.7007\n",
      "Fold 4, MAPE: 368096648888320.0000\n",
      "Epoch 1/3, Train Loss: 7943.5884, Validation Loss: 5589.8162\n",
      "Epoch 2/3, Train Loss: 4632.3866, Validation Loss: 2946.8170\n",
      "Epoch 3/3, Train Loss: 2377.5932, Validation Loss: 1989.6642\n",
      "Fold 5, MAPE: 1314383338668032.0000\n",
      "Epoch 1/3, Train Loss: 7522.1628, Validation Loss: 5915.8132\n",
      "Epoch 2/3, Train Loss: 3916.1825, Validation Loss: 2584.3489\n",
      "Epoch 3/3, Train Loss: 2039.5588, Validation Loss: 1560.1684\n",
      "Fold 6, MAPE: 1.5018\n",
      "Epoch 1/3, Train Loss: 7295.6547, Validation Loss: 5109.5673\n",
      "Epoch 2/3, Train Loss: 3299.1030, Validation Loss: 2203.3948\n",
      "Epoch 3/3, Train Loss: 1794.5439, Validation Loss: 1749.5425\n",
      "Fold 7, MAPE: 2967883604819968.0000\n",
      "Epoch 1/3, Train Loss: 7039.6725, Validation Loss: 4729.5735\n",
      "Epoch 2/3, Train Loss: 2870.2909, Validation Loss: 1693.3397\n",
      "Epoch 3/3, Train Loss: 1707.4089, Validation Loss: 1332.1556\n",
      "Fold 8, MAPE: 3628103561641984.0000\n",
      "Epoch 1/3, Train Loss: 6817.4159, Validation Loss: 4202.2714\n",
      "Epoch 2/3, Train Loss: 2532.7933, Validation Loss: 1649.4635\n",
      "Epoch 3/3, Train Loss: 1646.5590, Validation Loss: 1486.2091\n",
      "Fold 9, MAPE: 1055210113859584.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1244319268732928.0000\n",
      "Epoch 1/3, Train Loss: 8947.3976, Validation Loss: 9745.5855\n",
      "Epoch 2/3, Train Loss: 8759.1912, Validation Loss: 9539.3474\n",
      "Epoch 3/3, Train Loss: 8561.5158, Validation Loss: 9311.3457\n",
      "Fold 0, MAPE: 0.9387\n",
      "Epoch 1/3, Train Loss: 9290.2815, Validation Loss: 8241.3694\n",
      "Epoch 2/3, Train Loss: 8845.9372, Validation Loss: 7792.0875\n",
      "Epoch 3/3, Train Loss: 8336.1580, Validation Loss: 7290.8356\n",
      "Fold 1, MAPE: 1086883283075072.0000\n",
      "Epoch 1/3, Train Loss: 8812.6563, Validation Loss: 8512.8482\n",
      "Epoch 2/3, Train Loss: 8129.5559, Validation Loss: 7755.2486\n",
      "Epoch 3/3, Train Loss: 7351.4059, Validation Loss: 6921.8499\n",
      "Fold 2, MAPE: 85980505702400.0000\n",
      "Epoch 1/3, Train Loss: 8681.9463, Validation Loss: 8642.6394\n",
      "Epoch 2/3, Train Loss: 7701.7213, Validation Loss: 7530.9096\n",
      "Epoch 3/3, Train Loss: 6586.5182, Validation Loss: 6335.2084\n",
      "Fold 3, MAPE: 248167958315008.0000\n",
      "Epoch 1/3, Train Loss: 8693.2640, Validation Loss: 8583.5322\n",
      "Epoch 2/3, Train Loss: 7421.2244, Validation Loss: 7132.4492\n",
      "Epoch 3/3, Train Loss: 6003.0703, Validation Loss: 5626.4613\n",
      "Fold 4, MAPE: 162843215265792.0000\n",
      "Epoch 1/3, Train Loss: 8626.8810, Validation Loss: 7006.0827\n",
      "Epoch 2/3, Train Loss: 7025.0360, Validation Loss: 5469.5697\n",
      "Epoch 3/3, Train Loss: 5294.8481, Validation Loss: 4020.3768\n",
      "Fold 5, MAPE: 627277020790784.0000\n",
      "Epoch 1/3, Train Loss: 8400.2809, Validation Loss: 7951.1652\n",
      "Epoch 2/3, Train Loss: 6512.2626, Validation Loss: 5798.8860\n",
      "Epoch 3/3, Train Loss: 4571.4071, Validation Loss: 3866.9042\n",
      "Fold 6, MAPE: 1.1101\n",
      "Epoch 1/3, Train Loss: 8318.4130, Validation Loss: 7320.8719\n",
      "Epoch 2/3, Train Loss: 6109.4114, Validation Loss: 5041.1442\n",
      "Epoch 3/3, Train Loss: 3997.8632, Validation Loss: 3223.3050\n",
      "Fold 7, MAPE: 1744663362928640.0000\n",
      "Epoch 1/3, Train Loss: 8211.2644, Validation Loss: 7373.2731\n",
      "Epoch 2/3, Train Loss: 5693.0626, Validation Loss: 4625.4915\n",
      "Epoch 3/3, Train Loss: 3461.9401, Validation Loss: 2631.0074\n",
      "Fold 8, MAPE: 2360571739504640.0000\n",
      "Epoch 1/3, Train Loss: 8128.9389, Validation Loss: 6982.2013\n",
      "Epoch 2/3, Train Loss: 5333.0497, Validation Loss: 4106.1483\n",
      "Epoch 3/3, Train Loss: 3046.2555, Validation Loss: 2308.6608\n",
      "Fold 9, MAPE: 743973094162432.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 706036050690048.0000\n",
      "Epoch 1/3, Train Loss: 8869.7439, Validation Loss: 9553.8014\n",
      "Epoch 2/3, Train Loss: 8487.5781, Validation Loss: 9101.6136\n",
      "Epoch 3/3, Train Loss: 8051.4360, Validation Loss: 8596.2389\n",
      "Fold 0, MAPE: 0.9027\n",
      "Epoch 1/3, Train Loss: 9088.0205, Validation Loss: 7822.0495\n",
      "Epoch 2/3, Train Loss: 8131.4957, Validation Loss: 6837.3006\n",
      "Epoch 3/3, Train Loss: 7023.9052, Validation Loss: 5762.2170\n",
      "Fold 1, MAPE: 2398903517315072.0000\n",
      "Epoch 1/3, Train Loss: 8543.9167, Validation Loss: 7857.3535\n",
      "Epoch 2/3, Train Loss: 7053.1702, Validation Loss: 6166.7078\n",
      "Epoch 3/3, Train Loss: 5385.8709, Validation Loss: 4482.9176\n",
      "Fold 2, MAPE: 199270326075392.0000\n",
      "Epoch 1/3, Train Loss: 8221.7025, Validation Loss: 7589.2995\n",
      "Epoch 2/3, Train Loss: 6088.8036, Validation Loss: 5226.8981\n",
      "Epoch 3/3, Train Loss: 3993.3796, Validation Loss: 3265.3892\n",
      "Fold 3, MAPE: 581076661567488.0000\n",
      "Epoch 1/3, Train Loss: 8114.7233, Validation Loss: 7208.1390\n",
      "Epoch 2/3, Train Loss: 5384.8520, Validation Loss: 4293.4479\n",
      "Epoch 3/3, Train Loss: 3084.2915, Validation Loss: 2393.5842\n",
      "Fold 4, MAPE: 367823381594112.0000\n",
      "Epoch 1/3, Train Loss: 7877.5321, Validation Loss: 5521.8592\n",
      "Epoch 2/3, Train Loss: 4587.5192, Validation Loss: 2930.3427\n",
      "Epoch 3/3, Train Loss: 2376.4461, Validation Loss: 1992.0712\n",
      "Fold 5, MAPE: 1311408268509184.0000\n",
      "Epoch 1/3, Train Loss: 7567.5709, Validation Loss: 5954.6814\n",
      "Epoch 2/3, Train Loss: 3942.7117, Validation Loss: 2592.2976\n",
      "Epoch 3/3, Train Loss: 2050.3944, Validation Loss: 1558.5939\n",
      "Fold 6, MAPE: 1.5026\n",
      "Epoch 1/3, Train Loss: 7237.1051, Validation Loss: 5061.5061\n",
      "Epoch 2/3, Train Loss: 3278.6070, Validation Loss: 2202.2387\n",
      "Epoch 3/3, Train Loss: 1798.8408, Validation Loss: 1750.0259\n",
      "Fold 7, MAPE: 2969934720139264.0000\n",
      "Epoch 1/3, Train Loss: 6992.2820, Validation Loss: 4651.6744\n",
      "Epoch 2/3, Train Loss: 2845.3292, Validation Loss: 1685.8621\n",
      "Epoch 3/3, Train Loss: 1716.6997, Validation Loss: 1333.1675\n",
      "Fold 8, MAPE: 3625202848104448.0000\n",
      "Epoch 1/3, Train Loss: 6758.4787, Validation Loss: 4085.1794\n",
      "Epoch 2/3, Train Loss: 2474.0230, Validation Loss: 1635.5608\n",
      "Epoch 3/3, Train Loss: 1655.0860, Validation Loss: 1487.1901\n",
      "Fold 9, MAPE: 1053325495631872.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1250694476595200.0000\n",
      "Epoch 1/3, Train Loss: 8951.5858, Validation Loss: 9734.0173\n",
      "Epoch 2/3, Train Loss: 8752.7224, Validation Loss: 9517.9850\n",
      "Epoch 3/3, Train Loss: 8546.7097, Validation Loss: 9282.2885\n",
      "Fold 0, MAPE: 0.9366\n",
      "Epoch 1/3, Train Loss: 9321.6964, Validation Loss: 8258.4685\n",
      "Epoch 2/3, Train Loss: 8860.8171, Validation Loss: 7797.0448\n",
      "Epoch 3/3, Train Loss: 8344.9950, Validation Loss: 7290.4313\n",
      "Fold 1, MAPE: 1084937394454528.0000\n",
      "Epoch 1/3, Train Loss: 8821.3851, Validation Loss: 8508.5476\n",
      "Epoch 2/3, Train Loss: 8124.0868, Validation Loss: 7745.9210\n",
      "Epoch 3/3, Train Loss: 7349.4093, Validation Loss: 6918.0482\n",
      "Fold 2, MAPE: 86135560732672.0000\n",
      "Epoch 1/3, Train Loss: 8640.1912, Validation Loss: 8594.8909\n",
      "Epoch 2/3, Train Loss: 7662.0501, Validation Loss: 7486.1110\n",
      "Epoch 3/3, Train Loss: 6546.3243, Validation Loss: 6294.5001\n",
      "Fold 3, MAPE: 251706608713728.0000\n",
      "Epoch 1/3, Train Loss: 8681.0582, Validation Loss: 8554.7490\n",
      "Epoch 2/3, Train Loss: 7376.9735, Validation Loss: 7061.8770\n",
      "Epoch 3/3, Train Loss: 5925.9821, Validation Loss: 5530.0572\n",
      "Fold 4, MAPE: 167372342165504.0000\n",
      "Epoch 1/3, Train Loss: 8638.6648, Validation Loss: 6999.8417\n",
      "Epoch 2/3, Train Loss: 7018.3700, Validation Loss: 5460.6635\n",
      "Epoch 3/3, Train Loss: 5288.4985, Validation Loss: 4014.7119\n",
      "Fold 5, MAPE: 628429481312256.0000\n",
      "Epoch 1/3, Train Loss: 8384.4397, Validation Loss: 7935.5062\n",
      "Epoch 2/3, Train Loss: 6515.6614, Validation Loss: 5818.7766\n",
      "Epoch 3/3, Train Loss: 4601.7900, Validation Loss: 3911.7095\n",
      "Fold 6, MAPE: 1.1063\n",
      "Epoch 1/3, Train Loss: 8339.6093, Validation Loss: 7315.1750\n",
      "Epoch 2/3, Train Loss: 6098.1864, Validation Loss: 5022.9584\n",
      "Epoch 3/3, Train Loss: 3990.4506, Validation Loss: 3216.5312\n",
      "Fold 7, MAPE: 1742872630001664.0000\n",
      "Epoch 1/3, Train Loss: 8214.0980, Validation Loss: 7343.5947\n",
      "Epoch 2/3, Train Loss: 5669.0665, Validation Loss: 4594.9078\n",
      "Epoch 3/3, Train Loss: 3450.2133, Validation Loss: 2625.3301\n",
      "Fold 8, MAPE: 2363882622418944.0000\n",
      "Epoch 1/3, Train Loss: 8105.1303, Validation Loss: 6925.2038\n",
      "Epoch 2/3, Train Loss: 5276.5086, Validation Loss: 4049.1483\n",
      "Epoch 3/3, Train Loss: 3012.2629, Validation Loss: 2280.9580\n",
      "Fold 9, MAPE: 749801431891968.0000\n",
      "Tested params: {'hidden_size': 32, 'num_layers': 3, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 707513854984192.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8859.7382, Validation Loss: 9544.6528\n",
      "Epoch 2/3, Train Loss: 8474.4795, Validation Loss: 9098.4099\n",
      "Epoch 3/3, Train Loss: 8045.6660, Validation Loss: 8595.5969\n",
      "Fold 0, MAPE: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9107.3330, Validation Loss: 7849.1900\n",
      "Epoch 2/3, Train Loss: 8163.7895, Validation Loss: 6874.7182\n",
      "Epoch 3/3, Train Loss: 7056.1699, Validation Loss: 5787.1641\n",
      "Fold 1, MAPE: 2374613598208000.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8508.0419, Validation Loss: 7826.1831\n",
      "Epoch 2/3, Train Loss: 7020.5530, Validation Loss: 6140.8332\n",
      "Epoch 3/3, Train Loss: 5349.4806, Validation Loss: 4439.7650\n",
      "Fold 2, MAPE: 201607174160384.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8252.3023, Validation Loss: 7644.7715\n",
      "Epoch 2/3, Train Loss: 6144.0558, Validation Loss: 5269.5632\n",
      "Epoch 3/3, Train Loss: 4007.2756, Validation Loss: 3264.5586\n",
      "Fold 3, MAPE: 581198933917696.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8094.2065, Validation Loss: 7192.6512\n",
      "Epoch 2/3, Train Loss: 5351.9480, Validation Loss: 4243.8924\n",
      "Epoch 3/3, Train Loss: 3038.8358, Validation Loss: 2355.4920\n",
      "Fold 4, MAPE: 371642043727872.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7939.4518, Validation Loss: 5587.4819\n",
      "Epoch 2/3, Train Loss: 4638.4148, Validation Loss: 2955.0197\n",
      "Epoch 3/3, Train Loss: 2385.5766, Validation Loss: 1993.3012\n",
      "Fold 5, MAPE: 1309997505970176.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7535.8701, Validation Loss: 5900.1424\n",
      "Epoch 2/3, Train Loss: 3884.1054, Validation Loss: 2544.3978\n",
      "Epoch 3/3, Train Loss: 2021.8503, Validation Loss: 1552.2846\n",
      "Fold 6, MAPE: 1.5061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7350.4014, Validation Loss: 5180.6882\n",
      "Epoch 2/3, Train Loss: 3344.5483, Validation Loss: 2226.0980\n",
      "Epoch 3/3, Train Loss: 1796.7259, Validation Loss: 1750.5417\n",
      "Fold 7, MAPE: 2966942738546688.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7096.4936, Validation Loss: 4809.5555\n",
      "Epoch 2/3, Train Loss: 2928.5659, Validation Loss: 1727.8492\n",
      "Epoch 3/3, Train Loss: 1719.7909, Validation Loss: 1335.0393\n",
      "Fold 8, MAPE: 3618823211057152.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6777.6303, Validation Loss: 4115.6499\n",
      "Epoch 2/3, Train Loss: 2477.1505, Validation Loss: 1633.8766\n",
      "Epoch 3/3, Train Loss: 1643.9975, Validation Loss: 1485.3775\n",
      "Fold 9, MAPE: 1056936690712576.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1248176283582464.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8946.8182, Validation Loss: 9728.8983\n",
      "Epoch 2/3, Train Loss: 8741.3466, Validation Loss: 9512.1407\n",
      "Epoch 3/3, Train Loss: 8536.3592, Validation Loss: 9279.1007\n",
      "Fold 0, MAPE: 0.9364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9302.6280, Validation Loss: 8250.1982\n",
      "Epoch 2/3, Train Loss: 8855.3307, Validation Loss: 7804.1803\n",
      "Epoch 3/3, Train Loss: 8357.3043, Validation Loss: 7312.4236\n",
      "Fold 1, MAPE: 1067545998131200.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8819.1684, Validation Loss: 8508.0286\n",
      "Epoch 2/3, Train Loss: 8122.3271, Validation Loss: 7740.2781\n",
      "Epoch 3/3, Train Loss: 7333.1573, Validation Loss: 6900.2501\n",
      "Fold 2, MAPE: 86817235795968.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8687.8714, Validation Loss: 8653.6435\n",
      "Epoch 2/3, Train Loss: 7709.9072, Validation Loss: 7537.1179\n",
      "Epoch 3/3, Train Loss: 6588.9483, Validation Loss: 6329.1383\n",
      "Fold 3, MAPE: 248689964613632.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8649.6116, Validation Loss: 8529.1430\n",
      "Epoch 2/3, Train Loss: 7364.5359, Validation Loss: 7069.4864\n",
      "Epoch 3/3, Train Loss: 5942.8291, Validation Loss: 5564.1974\n",
      "Fold 4, MAPE: 165778238210048.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8636.3631, Validation Loss: 6999.9776\n",
      "Epoch 2/3, Train Loss: 6999.6370, Validation Loss: 5436.8345\n",
      "Epoch 3/3, Train Loss: 5252.0977, Validation Loss: 3976.9248\n",
      "Fold 5, MAPE: 635923125501952.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8417.9835, Validation Loss: 7971.1336\n",
      "Epoch 2/3, Train Loss: 6540.6444, Validation Loss: 5844.3113\n",
      "Epoch 3/3, Train Loss: 4613.6919, Validation Loss: 3907.9908\n",
      "Fold 6, MAPE: 1.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8378.8601, Validation Loss: 7389.8244\n",
      "Epoch 2/3, Train Loss: 6176.0320, Validation Loss: 5094.9486\n",
      "Epoch 3/3, Train Loss: 4034.8733, Validation Loss: 3240.7844\n",
      "Fold 7, MAPE: 1733851453849600.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8196.4962, Validation Loss: 7357.1736\n",
      "Epoch 2/3, Train Loss: 5689.4478, Validation Loss: 4626.2402\n",
      "Epoch 3/3, Train Loss: 3471.3996, Validation Loss: 2640.5658\n",
      "Fold 8, MAPE: 2355108809539584.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8098.0614, Validation Loss: 6944.0216\n",
      "Epoch 2/3, Train Loss: 5304.1770, Validation Loss: 4073.3824\n",
      "Epoch 3/3, Train Loss: 3014.2249, Validation Loss: 2282.8550\n",
      "Fold 9, MAPE: 749411126738944.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 704312560844800.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8871.2677, Validation Loss: 9554.5140\n",
      "Epoch 2/3, Train Loss: 8489.0198, Validation Loss: 9111.7932\n",
      "Epoch 3/3, Train Loss: 8066.5410, Validation Loss: 8621.6442\n",
      "Fold 0, MAPE: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9130.2843, Validation Loss: 7860.1523\n",
      "Epoch 2/3, Train Loss: 8166.4638, Validation Loss: 6861.9271\n",
      "Epoch 3/3, Train Loss: 7039.6670, Validation Loss: 5770.6455\n",
      "Fold 1, MAPE: 2392132501372928.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8541.7695, Validation Loss: 7847.0253\n",
      "Epoch 2/3, Train Loss: 7032.1177, Validation Loss: 6135.6299\n",
      "Epoch 3/3, Train Loss: 5340.9639, Validation Loss: 4433.5049\n",
      "Fold 2, MAPE: 201983185125376.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8272.0631, Validation Loss: 7648.3938\n",
      "Epoch 2/3, Train Loss: 6129.8644, Validation Loss: 5251.2122\n",
      "Epoch 3/3, Train Loss: 3997.5339, Validation Loss: 3267.0179\n",
      "Fold 3, MAPE: 580829969383424.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8094.0031, Validation Loss: 7188.1656\n",
      "Epoch 2/3, Train Loss: 5359.9604, Validation Loss: 4276.2263\n",
      "Epoch 3/3, Train Loss: 3084.9778, Validation Loss: 2391.8716\n",
      "Fold 4, MAPE: 367968303185920.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7910.4617, Validation Loss: 5571.4155\n",
      "Epoch 2/3, Train Loss: 4623.2015, Validation Loss: 2940.0070\n",
      "Epoch 3/3, Train Loss: 2379.5334, Validation Loss: 1989.7561\n",
      "Fold 5, MAPE: 1314199057727488.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7537.7681, Validation Loss: 5914.6568\n",
      "Epoch 2/3, Train Loss: 3915.7639, Validation Loss: 2569.1578\n",
      "Epoch 3/3, Train Loss: 2044.2436, Validation Loss: 1557.6923\n",
      "Fold 6, MAPE: 1.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7323.1255, Validation Loss: 5156.2347\n",
      "Epoch 2/3, Train Loss: 3340.6275, Validation Loss: 2221.3386\n",
      "Epoch 3/3, Train Loss: 1809.1764, Validation Loss: 1750.5251\n",
      "Fold 7, MAPE: 2963223296868352.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7045.2591, Validation Loss: 4746.8197\n",
      "Epoch 2/3, Train Loss: 2904.5950, Validation Loss: 1715.5278\n",
      "Epoch 3/3, Train Loss: 1727.8752, Validation Loss: 1335.3159\n",
      "Fold 8, MAPE: 3617787587067904.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6738.3542, Validation Loss: 4072.0545\n",
      "Epoch 2/3, Train Loss: 2468.4992, Validation Loss: 1632.1452\n",
      "Epoch 3/3, Train Loss: 1653.7828, Validation Loss: 1487.9704\n",
      "Fold 9, MAPE: 1051802057310208.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1248992595804160.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8966.5450, Validation Loss: 9751.4830\n",
      "Epoch 2/3, Train Loss: 8766.5177, Validation Loss: 9536.0156\n",
      "Epoch 3/3, Train Loss: 8559.3776, Validation Loss: 9300.7507\n",
      "Fold 0, MAPE: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9307.4709, Validation Loss: 8239.6089\n",
      "Epoch 2/3, Train Loss: 8849.6444, Validation Loss: 7791.0339\n",
      "Epoch 3/3, Train Loss: 8345.0632, Validation Loss: 7294.2506\n",
      "Fold 1, MAPE: 1082694683328512.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8834.6500, Validation Loss: 8518.1412\n",
      "Epoch 2/3, Train Loss: 8132.7662, Validation Loss: 7739.5312\n",
      "Epoch 3/3, Train Loss: 7327.3087, Validation Loss: 6883.4557\n",
      "Fold 2, MAPE: 87524881989632.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8668.9434, Validation Loss: 8619.8234\n",
      "Epoch 2/3, Train Loss: 7686.3210, Validation Loss: 7515.0318\n",
      "Epoch 3/3, Train Loss: 6578.7953, Validation Loss: 6324.3358\n",
      "Fold 3, MAPE: 249089446903808.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8716.7551, Validation Loss: 8597.5621\n",
      "Epoch 2/3, Train Loss: 7433.2991, Validation Loss: 7136.1728\n",
      "Epoch 3/3, Train Loss: 5998.0588, Validation Loss: 5612.4374\n",
      "Fold 4, MAPE: 163504724115456.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8644.9285, Validation Loss: 7001.6441\n",
      "Epoch 2/3, Train Loss: 7001.0340, Validation Loss: 5439.5702\n",
      "Epoch 3/3, Train Loss: 5265.1870, Validation Loss: 3989.0625\n",
      "Fold 5, MAPE: 633535861882880.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8400.8784, Validation Loss: 7932.3990\n",
      "Epoch 2/3, Train Loss: 6498.9407, Validation Loss: 5795.4076\n",
      "Epoch 3/3, Train Loss: 4579.8017, Validation Loss: 3882.1270\n",
      "Fold 6, MAPE: 1.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8344.5061, Validation Loss: 7335.5051\n",
      "Epoch 2/3, Train Loss: 6127.6016, Validation Loss: 5050.5694\n",
      "Epoch 3/3, Train Loss: 4007.8530, Validation Loss: 3226.9337\n",
      "Fold 7, MAPE: 1742487425122304.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8202.5982, Validation Loss: 7343.1472\n",
      "Epoch 2/3, Train Loss: 5676.8783, Validation Loss: 4607.7710\n",
      "Epoch 3/3, Train Loss: 3468.6694, Validation Loss: 2640.3791\n",
      "Fold 8, MAPE: 2355070423269376.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8076.9413, Validation Loss: 6912.4151\n",
      "Epoch 2/3, Train Loss: 5287.3282, Validation Loss: 4078.2896\n",
      "Epoch 3/3, Train Loss: 3042.8598, Validation Loss: 2305.1239\n",
      "Fold 9, MAPE: 744705184759808.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 705861232099328.0000\n",
      "Epoch 1/3, Train Loss: 8839.1078, Validation Loss: 9523.9358\n",
      "Epoch 2/3, Train Loss: 8453.1402, Validation Loss: 9073.9345\n",
      "Epoch 3/3, Train Loss: 8024.2073, Validation Loss: 8571.0145\n",
      "Fold 0, MAPE: 0.9016\n",
      "Epoch 1/3, Train Loss: 9077.9125, Validation Loss: 7826.8029\n",
      "Epoch 2/3, Train Loss: 8128.1389, Validation Loss: 6836.7070\n",
      "Epoch 3/3, Train Loss: 7018.7597, Validation Loss: 5755.9439\n",
      "Fold 1, MAPE: 2406488161124352.0000\n",
      "Epoch 1/3, Train Loss: 8507.4079, Validation Loss: 7819.5908\n",
      "Epoch 2/3, Train Loss: 7017.0908, Validation Loss: 6136.3096\n",
      "Epoch 3/3, Train Loss: 5348.6869, Validation Loss: 4446.4908\n",
      "Fold 2, MAPE: 201242303266816.0000\n",
      "Epoch 1/3, Train Loss: 8235.2546, Validation Loss: 7627.0579\n",
      "Epoch 2/3, Train Loss: 6133.2049, Validation Loss: 5263.8763\n",
      "Epoch 3/3, Train Loss: 4010.2510, Validation Loss: 3274.5425\n",
      "Fold 3, MAPE: 579738510819328.0000\n",
      "Epoch 1/3, Train Loss: 8084.4575, Validation Loss: 7201.2368\n",
      "Epoch 2/3, Train Loss: 5386.6989, Validation Loss: 4302.2790\n",
      "Epoch 3/3, Train Loss: 3085.4471, Validation Loss: 2395.0308\n",
      "Fold 4, MAPE: 367704867340288.0000\n",
      "Epoch 1/3, Train Loss: 7925.8148, Validation Loss: 5592.2421\n",
      "Epoch 2/3, Train Loss: 4634.3661, Validation Loss: 2939.5542\n",
      "Epoch 3/3, Train Loss: 2365.8357, Validation Loss: 1986.2134\n",
      "Fold 5, MAPE: 1318643006701568.0000\n",
      "Epoch 1/3, Train Loss: 7517.6254, Validation Loss: 5903.7750\n",
      "Epoch 2/3, Train Loss: 3910.9698, Validation Loss: 2574.1698\n",
      "Epoch 3/3, Train Loss: 2036.5216, Validation Loss: 1556.0629\n",
      "Fold 6, MAPE: 1.5041\n",
      "Epoch 1/3, Train Loss: 7285.6506, Validation Loss: 5108.9211\n",
      "Epoch 2/3, Train Loss: 3300.1713, Validation Loss: 2208.7887\n",
      "Epoch 3/3, Train Loss: 1793.9905, Validation Loss: 1749.7463\n",
      "Fold 7, MAPE: 2970141683875840.0000\n",
      "Epoch 1/3, Train Loss: 7030.0747, Validation Loss: 4729.5813\n",
      "Epoch 2/3, Train Loss: 2883.6101, Validation Loss: 1706.0705\n",
      "Epoch 3/3, Train Loss: 1713.3350, Validation Loss: 1334.4742\n",
      "Fold 8, MAPE: 3620512743817216.0000\n",
      "Epoch 1/3, Train Loss: 6713.5828, Validation Loss: 4059.1417\n",
      "Epoch 2/3, Train Loss: 2455.4759, Validation Loss: 1628.9395\n",
      "Epoch 3/3, Train Loss: 1641.1828, Validation Loss: 1485.0185\n",
      "Fold 9, MAPE: 1057804878086144.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1252227645702144.0000\n",
      "Epoch 1/3, Train Loss: 8936.7872, Validation Loss: 9734.8081\n",
      "Epoch 2/3, Train Loss: 8747.9883, Validation Loss: 9524.9887\n",
      "Epoch 3/3, Train Loss: 8550.4996, Validation Loss: 9297.7670\n",
      "Fold 0, MAPE: 0.9378\n",
      "Epoch 1/3, Train Loss: 9291.2499, Validation Loss: 8236.9578\n",
      "Epoch 2/3, Train Loss: 8841.0081, Validation Loss: 7786.2752\n",
      "Epoch 3/3, Train Loss: 8338.3820, Validation Loss: 7290.7725\n",
      "Fold 1, MAPE: 1083986059198464.0000\n",
      "Epoch 1/3, Train Loss: 8822.7541, Validation Loss: 8523.4133\n",
      "Epoch 2/3, Train Loss: 8144.0150, Validation Loss: 7772.8701\n",
      "Epoch 3/3, Train Loss: 7373.0658, Validation Loss: 6942.9736\n",
      "Fold 2, MAPE: 85117955473408.0000\n",
      "Epoch 1/3, Train Loss: 8665.1577, Validation Loss: 8630.4316\n",
      "Epoch 2/3, Train Loss: 7690.1835, Validation Loss: 7519.7842\n",
      "Epoch 3/3, Train Loss: 6573.9769, Validation Loss: 6316.6192\n",
      "Fold 3, MAPE: 249793435664384.0000\n",
      "Epoch 1/3, Train Loss: 8677.1548, Validation Loss: 8565.3650\n",
      "Epoch 2/3, Train Loss: 7404.7226, Validation Loss: 7113.2853\n",
      "Epoch 3/3, Train Loss: 5980.8446, Validation Loss: 5597.0202\n",
      "Fold 4, MAPE: 164219332853760.0000\n",
      "Epoch 1/3, Train Loss: 8651.9340, Validation Loss: 7025.4455\n",
      "Epoch 2/3, Train Loss: 7038.5778, Validation Loss: 5486.4282\n",
      "Epoch 3/3, Train Loss: 5321.8684, Validation Loss: 4042.4026\n",
      "Fold 5, MAPE: 622972725362688.0000\n",
      "Epoch 1/3, Train Loss: 8386.0425, Validation Loss: 7956.6471\n",
      "Epoch 2/3, Train Loss: 6532.0529, Validation Loss: 5839.1904\n",
      "Epoch 3/3, Train Loss: 4613.0415, Validation Loss: 3915.2771\n",
      "Fold 6, MAPE: 1.1061\n",
      "Epoch 1/3, Train Loss: 8314.4127, Validation Loss: 7310.6246\n",
      "Epoch 2/3, Train Loss: 6100.6684, Validation Loss: 5032.9241\n",
      "Epoch 3/3, Train Loss: 3994.5651, Validation Loss: 3222.7777\n",
      "Fold 7, MAPE: 1739855818129408.0000\n",
      "Epoch 1/3, Train Loss: 8195.0125, Validation Loss: 7347.4994\n",
      "Epoch 2/3, Train Loss: 5675.3657, Validation Loss: 4610.1880\n",
      "Epoch 3/3, Train Loss: 3455.9719, Validation Loss: 2632.0258\n",
      "Fold 8, MAPE: 2360019299336192.0000\n",
      "Epoch 1/3, Train Loss: 8086.5299, Validation Loss: 6934.6195\n",
      "Epoch 2/3, Train Loss: 5300.8988, Validation Loss: 4070.6855\n",
      "Epoch 3/3, Train Loss: 3011.2045, Validation Loss: 2280.3135\n",
      "Fold 9, MAPE: 749861896978432.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 705582663204864.0000\n",
      "Epoch 1/3, Train Loss: 8875.2856, Validation Loss: 9552.6747\n",
      "Epoch 2/3, Train Loss: 8485.0216, Validation Loss: 9097.0356\n",
      "Epoch 3/3, Train Loss: 8043.2558, Validation Loss: 8584.6553\n",
      "Fold 0, MAPE: 0.9022\n",
      "Epoch 1/3, Train Loss: 9135.7760, Validation Loss: 7865.8152\n",
      "Epoch 2/3, Train Loss: 8178.6972, Validation Loss: 6884.5771\n",
      "Epoch 3/3, Train Loss: 7086.5436, Validation Loss: 5822.6280\n",
      "Fold 1, MAPE: 2342359199121408.0000\n",
      "Epoch 1/3, Train Loss: 8487.1099, Validation Loss: 7788.3780\n",
      "Epoch 2/3, Train Loss: 6992.7658, Validation Loss: 6121.4869\n",
      "Epoch 3/3, Train Loss: 5352.6314, Validation Loss: 4461.3424\n",
      "Fold 2, MAPE: 200460669550592.0000\n",
      "Epoch 1/3, Train Loss: 8269.5857, Validation Loss: 7649.1218\n",
      "Epoch 2/3, Train Loss: 6157.8863, Validation Loss: 5296.9139\n",
      "Epoch 3/3, Train Loss: 4052.8521, Validation Loss: 3318.4224\n",
      "Fold 3, MAPE: 573529800048640.0000\n",
      "Epoch 1/3, Train Loss: 8087.7390, Validation Loss: 7169.7147\n",
      "Epoch 2/3, Train Loss: 5331.2084, Validation Loss: 4236.3090\n",
      "Epoch 3/3, Train Loss: 3050.3248, Validation Loss: 2363.1756\n",
      "Fold 4, MAPE: 370854085001216.0000\n",
      "Epoch 1/3, Train Loss: 7894.9459, Validation Loss: 5537.6918\n",
      "Epoch 2/3, Train Loss: 4587.3957, Validation Loss: 2918.3411\n",
      "Epoch 3/3, Train Loss: 2362.0981, Validation Loss: 1987.1031\n",
      "Fold 5, MAPE: 1318106404225024.0000\n",
      "Epoch 1/3, Train Loss: 7505.6393, Validation Loss: 5858.7784\n",
      "Epoch 2/3, Train Loss: 3878.0125, Validation Loss: 2550.4381\n",
      "Epoch 3/3, Train Loss: 2033.3813, Validation Loss: 1553.7020\n",
      "Fold 6, MAPE: 1.5053\n",
      "Epoch 1/3, Train Loss: 7296.3852, Validation Loss: 5108.5630\n",
      "Epoch 2/3, Train Loss: 3310.7571, Validation Loss: 2211.6778\n",
      "Epoch 3/3, Train Loss: 1800.8769, Validation Loss: 1750.8296\n",
      "Fold 7, MAPE: 2966778724483072.0000\n",
      "Epoch 1/3, Train Loss: 7028.5034, Validation Loss: 4714.0507\n",
      "Epoch 2/3, Train Loss: 2882.5531, Validation Loss: 1702.1716\n",
      "Epoch 3/3, Train Loss: 1726.3785, Validation Loss: 1334.9584\n",
      "Fold 8, MAPE: 3618949375721472.0000\n",
      "Epoch 1/3, Train Loss: 6779.6057, Validation Loss: 4129.4877\n",
      "Epoch 2/3, Train Loss: 2495.5933, Validation Loss: 1637.7277\n",
      "Epoch 3/3, Train Loss: 1652.9953, Validation Loss: 1485.9797\n",
      "Fold 9, MAPE: 1055623168917504.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1244666221559808.0000\n",
      "Epoch 1/3, Train Loss: 8937.2291, Validation Loss: 9708.4855\n",
      "Epoch 2/3, Train Loss: 8728.0893, Validation Loss: 9493.0436\n",
      "Epoch 3/3, Train Loss: 8526.2908, Validation Loss: 9261.6624\n",
      "Fold 0, MAPE: 0.9351\n",
      "Epoch 1/3, Train Loss: 9302.0163, Validation Loss: 8247.0420\n",
      "Epoch 2/3, Train Loss: 8857.2252, Validation Loss: 7803.2863\n",
      "Epoch 3/3, Train Loss: 8354.7749, Validation Loss: 7308.6901\n",
      "Fold 1, MAPE: 1071476027424768.0000\n",
      "Epoch 1/3, Train Loss: 8816.3623, Validation Loss: 8498.4080\n",
      "Epoch 2/3, Train Loss: 8114.0412, Validation Loss: 7722.9180\n",
      "Epoch 3/3, Train Loss: 7314.8539, Validation Loss: 6871.1443\n",
      "Fold 2, MAPE: 88019591757824.0000\n",
      "Epoch 1/3, Train Loss: 8666.4637, Validation Loss: 8619.0697\n",
      "Epoch 2/3, Train Loss: 7681.4065, Validation Loss: 7506.4613\n",
      "Epoch 3/3, Train Loss: 6564.1017, Validation Loss: 6305.4636\n",
      "Fold 3, MAPE: 250772218445824.0000\n",
      "Epoch 1/3, Train Loss: 8671.8961, Validation Loss: 8534.8373\n",
      "Epoch 2/3, Train Loss: 7366.8977, Validation Loss: 7068.5818\n",
      "Epoch 3/3, Train Loss: 5946.9595, Validation Loss: 5561.9453\n",
      "Fold 4, MAPE: 165872509386752.0000\n",
      "Epoch 1/3, Train Loss: 8688.5228, Validation Loss: 7053.0207\n",
      "Epoch 2/3, Train Loss: 7064.9978, Validation Loss: 5497.7241\n",
      "Epoch 3/3, Train Loss: 5322.8626, Validation Loss: 4034.1817\n",
      "Fold 5, MAPE: 624578506260480.0000\n",
      "Epoch 1/3, Train Loss: 8394.9328, Validation Loss: 7948.5821\n",
      "Epoch 2/3, Train Loss: 6519.4755, Validation Loss: 5815.9469\n",
      "Epoch 3/3, Train Loss: 4603.1392, Validation Loss: 3901.3649\n",
      "Fold 6, MAPE: 1.1072\n",
      "Epoch 1/3, Train Loss: 8342.5632, Validation Loss: 7332.2725\n",
      "Epoch 2/3, Train Loss: 6115.7549, Validation Loss: 5039.4195\n",
      "Epoch 3/3, Train Loss: 4001.8200, Validation Loss: 3220.9170\n",
      "Fold 7, MAPE: 1744337079631872.0000\n",
      "Epoch 1/3, Train Loss: 8193.2571, Validation Loss: 7346.4523\n",
      "Epoch 2/3, Train Loss: 5682.1781, Validation Loss: 4610.3182\n",
      "Epoch 3/3, Train Loss: 3455.0452, Validation Loss: 2621.3297\n",
      "Fold 8, MAPE: 2366350618001408.0000\n",
      "Epoch 1/3, Train Loss: 8091.1971, Validation Loss: 6900.9699\n",
      "Epoch 2/3, Train Loss: 5257.0878, Validation Loss: 4029.4147\n",
      "Epoch 3/3, Train Loss: 3001.1789, Validation Loss: 2269.1563\n",
      "Fold 9, MAPE: 752243657670656.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 706365018341376.0000\n",
      "Epoch 1/3, Train Loss: 8870.2477, Validation Loss: 9567.6573\n",
      "Epoch 2/3, Train Loss: 8501.6667, Validation Loss: 9134.5458\n",
      "Epoch 3/3, Train Loss: 8081.2926, Validation Loss: 8641.3423\n",
      "Fold 0, MAPE: 0.9047\n",
      "Epoch 1/3, Train Loss: 9075.4183, Validation Loss: 7815.6068\n",
      "Epoch 2/3, Train Loss: 8110.6916, Validation Loss: 6817.0965\n",
      "Epoch 3/3, Train Loss: 6996.5587, Validation Loss: 5738.6284\n",
      "Fold 1, MAPE: 2417910089777152.0000\n",
      "Epoch 1/3, Train Loss: 8528.3792, Validation Loss: 7858.7196\n",
      "Epoch 2/3, Train Loss: 7063.5714, Validation Loss: 6190.7635\n",
      "Epoch 3/3, Train Loss: 5402.7513, Validation Loss: 4492.9834\n",
      "Fold 2, MAPE: 198741709553664.0000\n",
      "Epoch 1/3, Train Loss: 8226.9586, Validation Loss: 7606.3162\n",
      "Epoch 2/3, Train Loss: 6104.3512, Validation Loss: 5241.8225\n",
      "Epoch 3/3, Train Loss: 4001.1952, Validation Loss: 3279.5392\n",
      "Fold 3, MAPE: 578988636372992.0000\n",
      "Epoch 1/3, Train Loss: 8085.8355, Validation Loss: 7188.1438\n",
      "Epoch 2/3, Train Loss: 5351.6509, Validation Loss: 4249.8643\n",
      "Epoch 3/3, Train Loss: 3050.5527, Validation Loss: 2362.5893\n",
      "Fold 4, MAPE: 370887303888896.0000\n",
      "Epoch 1/3, Train Loss: 7898.6147, Validation Loss: 5557.8765\n",
      "Epoch 2/3, Train Loss: 4598.5799, Validation Loss: 2919.8020\n",
      "Epoch 3/3, Train Loss: 2354.1182, Validation Loss: 1985.5541\n",
      "Fold 5, MAPE: 1319369124610048.0000\n",
      "Epoch 1/3, Train Loss: 7542.3287, Validation Loss: 5927.9521\n",
      "Epoch 2/3, Train Loss: 3917.1772, Validation Loss: 2571.8877\n",
      "Epoch 3/3, Train Loss: 2034.7027, Validation Loss: 1556.7171\n",
      "Fold 6, MAPE: 1.5037\n",
      "Epoch 1/3, Train Loss: 7331.3419, Validation Loss: 5150.1917\n",
      "Epoch 2/3, Train Loss: 3327.3152, Validation Loss: 2221.8546\n",
      "Epoch 3/3, Train Loss: 1799.6228, Validation Loss: 1750.7632\n",
      "Fold 7, MAPE: 2964733514743808.0000\n",
      "Epoch 1/3, Train Loss: 7034.2421, Validation Loss: 4712.3085\n",
      "Epoch 2/3, Train Loss: 2871.8255, Validation Loss: 1697.6846\n",
      "Epoch 3/3, Train Loss: 1713.6238, Validation Loss: 1333.6796\n",
      "Fold 8, MAPE: 3623291587657728.0000\n",
      "Epoch 1/3, Train Loss: 6743.6180, Validation Loss: 4072.8247\n",
      "Epoch 2/3, Train Loss: 2464.5264, Validation Loss: 1628.6383\n",
      "Epoch 3/3, Train Loss: 1639.4275, Validation Loss: 1485.1909\n",
      "Fold 9, MAPE: 1057336995086336.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1253125830737920.0000\n",
      "Epoch 1/3, Train Loss: 8946.5134, Validation Loss: 9735.2802\n",
      "Epoch 2/3, Train Loss: 8752.1870, Validation Loss: 9526.0498\n",
      "Epoch 3/3, Train Loss: 8550.5481, Validation Loss: 9294.8762\n",
      "Fold 0, MAPE: 0.9375\n",
      "Epoch 1/3, Train Loss: 9327.1119, Validation Loss: 8275.8762\n",
      "Epoch 2/3, Train Loss: 8881.8675, Validation Loss: 7829.0178\n",
      "Epoch 3/3, Train Loss: 8383.6917, Validation Loss: 7339.5273\n",
      "Fold 1, MAPE: 1044926351540224.0000\n",
      "Epoch 1/3, Train Loss: 8806.2318, Validation Loss: 8502.6300\n",
      "Epoch 2/3, Train Loss: 8109.7286, Validation Loss: 7730.0996\n",
      "Epoch 3/3, Train Loss: 7321.9125, Validation Loss: 6888.6999\n",
      "Fold 2, MAPE: 87320401281024.0000\n",
      "Epoch 1/3, Train Loss: 8645.5217, Validation Loss: 8607.8168\n",
      "Epoch 2/3, Train Loss: 7666.1486, Validation Loss: 7497.8494\n",
      "Epoch 3/3, Train Loss: 6560.2340, Validation Loss: 6306.7174\n",
      "Fold 3, MAPE: 250655616794624.0000\n",
      "Epoch 1/3, Train Loss: 8703.8952, Validation Loss: 8599.3389\n",
      "Epoch 2/3, Train Loss: 7434.6184, Validation Loss: 7146.6372\n",
      "Epoch 3/3, Train Loss: 6015.1730, Validation Loss: 5633.2133\n",
      "Fold 4, MAPE: 162536427094016.0000\n",
      "Epoch 1/3, Train Loss: 8672.2453, Validation Loss: 7051.0151\n",
      "Epoch 2/3, Train Loss: 7072.6917, Validation Loss: 5510.5029\n",
      "Epoch 3/3, Train Loss: 5341.8480, Validation Loss: 4047.2832\n",
      "Fold 5, MAPE: 621967434579968.0000\n",
      "Epoch 1/3, Train Loss: 8428.0060, Validation Loss: 8000.3782\n",
      "Epoch 2/3, Train Loss: 6571.5243, Validation Loss: 5868.1325\n",
      "Epoch 3/3, Train Loss: 4628.5411, Validation Loss: 3913.9299\n",
      "Fold 6, MAPE: 1.1061\n",
      "Epoch 1/3, Train Loss: 8360.9701, Validation Loss: 7368.6429\n",
      "Epoch 2/3, Train Loss: 6149.6605, Validation Loss: 5064.9599\n",
      "Epoch 3/3, Train Loss: 4005.3876, Validation Loss: 3223.1114\n",
      "Fold 7, MAPE: 1740776014872576.0000\n",
      "Epoch 1/3, Train Loss: 8206.9099, Validation Loss: 7376.4225\n",
      "Epoch 2/3, Train Loss: 5709.2210, Validation Loss: 4650.8383\n",
      "Epoch 3/3, Train Loss: 3494.8566, Validation Loss: 2663.9171\n",
      "Fold 8, MAPE: 2341870378156032.0000\n",
      "Epoch 1/3, Train Loss: 8104.5971, Validation Loss: 6934.6405\n",
      "Epoch 2/3, Train Loss: 5293.4963, Validation Loss: 4078.7420\n",
      "Epoch 3/3, Train Loss: 3028.2889, Validation Loss: 2296.7954\n",
      "Fold 9, MAPE: 746366464688128.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 699641918128128.0000\n",
      "Epoch 1/3, Train Loss: 8833.7254, Validation Loss: 9510.7934\n",
      "Epoch 2/3, Train Loss: 8450.0333, Validation Loss: 9060.6842\n",
      "Epoch 3/3, Train Loss: 8008.9494, Validation Loss: 8553.6206\n",
      "Fold 0, MAPE: 0.9008\n",
      "Epoch 1/3, Train Loss: 9111.0504, Validation Loss: 7849.5379\n",
      "Epoch 2/3, Train Loss: 8164.1032, Validation Loss: 6869.2158\n",
      "Epoch 3/3, Train Loss: 7057.7802, Validation Loss: 5799.1301\n",
      "Fold 1, MAPE: 2362564872765440.0000\n",
      "Epoch 1/3, Train Loss: 8532.6880, Validation Loss: 7826.8339\n",
      "Epoch 2/3, Train Loss: 7006.4743, Validation Loss: 6120.2297\n",
      "Epoch 3/3, Train Loss: 5338.4975, Validation Loss: 4443.2867\n",
      "Fold 2, MAPE: 201445022367744.0000\n",
      "Epoch 1/3, Train Loss: 8244.6361, Validation Loss: 7623.0537\n",
      "Epoch 2/3, Train Loss: 6137.7668, Validation Loss: 5269.6005\n",
      "Epoch 3/3, Train Loss: 4031.6770, Validation Loss: 3301.6466\n",
      "Fold 3, MAPE: 575888609509376.0000\n",
      "Epoch 1/3, Train Loss: 8105.9160, Validation Loss: 7198.1927\n",
      "Epoch 2/3, Train Loss: 5370.8378, Validation Loss: 4275.4474\n",
      "Epoch 3/3, Train Loss: 3072.5613, Validation Loss: 2383.4826\n",
      "Fold 4, MAPE: 368828034842624.0000\n",
      "Epoch 1/3, Train Loss: 7919.5355, Validation Loss: 5565.6100\n",
      "Epoch 2/3, Train Loss: 4615.4467, Validation Loss: 2938.6184\n",
      "Epoch 3/3, Train Loss: 2383.9830, Validation Loss: 1992.1356\n",
      "Fold 5, MAPE: 1311346796789760.0000\n",
      "Epoch 1/3, Train Loss: 7528.1399, Validation Loss: 5888.8002\n",
      "Epoch 2/3, Train Loss: 3898.6502, Validation Loss: 2566.1633\n",
      "Epoch 3/3, Train Loss: 2039.1627, Validation Loss: 1557.5499\n",
      "Fold 6, MAPE: 1.5033\n",
      "Epoch 1/3, Train Loss: 7293.0352, Validation Loss: 5149.7589\n",
      "Epoch 2/3, Train Loss: 3346.3684, Validation Loss: 2235.7169\n",
      "Epoch 3/3, Train Loss: 1816.0713, Validation Loss: 1751.8949\n",
      "Fold 7, MAPE: 2959203207479296.0000\n",
      "Epoch 1/3, Train Loss: 6990.6111, Validation Loss: 4653.2608\n",
      "Epoch 2/3, Train Loss: 2843.8520, Validation Loss: 1684.4508\n",
      "Epoch 3/3, Train Loss: 1719.6710, Validation Loss: 1333.1080\n",
      "Fold 8, MAPE: 3624872135622656.0000\n",
      "Epoch 1/3, Train Loss: 6784.8141, Validation Loss: 4128.1742\n",
      "Epoch 2/3, Train Loss: 2488.0966, Validation Loss: 1631.9811\n",
      "Epoch 3/3, Train Loss: 1653.4059, Validation Loss: 1486.0659\n",
      "Fold 9, MAPE: 1055591627751424.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1245974039101440.0000\n",
      "Epoch 1/3, Train Loss: 8936.5601, Validation Loss: 9713.3679\n",
      "Epoch 2/3, Train Loss: 8733.2488, Validation Loss: 9498.7762\n",
      "Epoch 3/3, Train Loss: 8528.7702, Validation Loss: 9265.3988\n",
      "Fold 0, MAPE: 0.9356\n",
      "Epoch 1/3, Train Loss: 9315.2062, Validation Loss: 8264.2395\n",
      "Epoch 2/3, Train Loss: 8869.3119, Validation Loss: 7807.4771\n",
      "Epoch 3/3, Train Loss: 8355.9395, Validation Loss: 7304.2086\n",
      "Fold 1, MAPE: 1073344539525120.0000\n",
      "Epoch 1/3, Train Loss: 8836.3024, Validation Loss: 8518.2398\n",
      "Epoch 2/3, Train Loss: 8127.1978, Validation Loss: 7738.3663\n",
      "Epoch 3/3, Train Loss: 7331.5089, Validation Loss: 6897.9653\n",
      "Fold 2, MAPE: 86930683330560.0000\n",
      "Epoch 1/3, Train Loss: 8661.6485, Validation Loss: 8615.1105\n",
      "Epoch 2/3, Train Loss: 7684.4647, Validation Loss: 7516.2528\n",
      "Epoch 3/3, Train Loss: 6585.4157, Validation Loss: 6331.1428\n",
      "Fold 3, MAPE: 248527863152640.0000\n",
      "Epoch 1/3, Train Loss: 8668.9308, Validation Loss: 8533.2068\n",
      "Epoch 2/3, Train Loss: 7377.8366, Validation Loss: 7081.9038\n",
      "Epoch 3/3, Train Loss: 5958.2373, Validation Loss: 5574.8282\n",
      "Fold 4, MAPE: 165262405926912.0000\n",
      "Epoch 1/3, Train Loss: 8669.8164, Validation Loss: 7036.6959\n",
      "Epoch 2/3, Train Loss: 7049.0898, Validation Loss: 5494.5410\n",
      "Epoch 3/3, Train Loss: 5332.3939, Validation Loss: 4048.1684\n",
      "Fold 5, MAPE: 621927437697024.0000\n",
      "Epoch 1/3, Train Loss: 8396.9891, Validation Loss: 7935.8064\n",
      "Epoch 2/3, Train Loss: 6502.9580, Validation Loss: 5793.3222\n",
      "Epoch 3/3, Train Loss: 4580.0228, Validation Loss: 3871.7257\n",
      "Fold 6, MAPE: 1.1097\n",
      "Epoch 1/3, Train Loss: 8339.7905, Validation Loss: 7337.6642\n",
      "Epoch 2/3, Train Loss: 6134.7890, Validation Loss: 5059.0428\n",
      "Epoch 3/3, Train Loss: 4022.4581, Validation Loss: 3234.9029\n",
      "Fold 7, MAPE: 1733572952064000.0000\n",
      "Epoch 1/3, Train Loss: 8189.6576, Validation Loss: 7335.2371\n",
      "Epoch 2/3, Train Loss: 5663.7018, Validation Loss: 4588.1052\n",
      "Epoch 3/3, Train Loss: 3441.1632, Validation Loss: 2617.7332\n",
      "Fold 8, MAPE: 2368195574890496.0000\n",
      "Epoch 1/3, Train Loss: 8051.3405, Validation Loss: 6850.1588\n",
      "Epoch 2/3, Train Loss: 5213.7258, Validation Loss: 3994.1118\n",
      "Epoch 3/3, Train Loss: 2976.9211, Validation Loss: 2257.6859\n",
      "Fold 9, MAPE: 754749502652416.0000\n",
      "Tested params: {'hidden_size': 64, 'num_layers': 3, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 705251145416704.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8842.3380, Validation Loss: 9539.3123\n",
      "Epoch 2/3, Train Loss: 8473.6451, Validation Loss: 9100.0421\n",
      "Epoch 3/3, Train Loss: 8051.9863, Validation Loss: 8606.6371\n",
      "Fold 0, MAPE: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9122.7935, Validation Loss: 7869.1037\n",
      "Epoch 2/3, Train Loss: 8181.5043, Validation Loss: 6889.5554\n",
      "Epoch 3/3, Train Loss: 7079.2981, Validation Loss: 5813.5215\n",
      "Fold 1, MAPE: 2348238204043264.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8548.8766, Validation Loss: 7874.4586\n",
      "Epoch 2/3, Train Loss: 7062.6231, Validation Loss: 6179.6611\n",
      "Epoch 3/3, Train Loss: 5381.4337, Validation Loss: 4472.7306\n",
      "Fold 2, MAPE: 199809914896384.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8223.1409, Validation Loss: 7599.4254\n",
      "Epoch 2/3, Train Loss: 6087.1396, Validation Loss: 5207.5494\n",
      "Epoch 3/3, Train Loss: 3965.0229, Validation Loss: 3242.4942\n",
      "Fold 3, MAPE: 584352513654784.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8113.2568, Validation Loss: 7200.1091\n",
      "Epoch 2/3, Train Loss: 5364.3464, Validation Loss: 4268.6703\n",
      "Epoch 3/3, Train Loss: 3066.8772, Validation Loss: 2373.8499\n",
      "Fold 4, MAPE: 369773531627520.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7899.3293, Validation Loss: 5548.1951\n",
      "Epoch 2/3, Train Loss: 4598.6460, Validation Loss: 2937.3130\n",
      "Epoch 3/3, Train Loss: 2373.8495, Validation Loss: 1990.8108\n",
      "Fold 5, MAPE: 1313265036558336.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7545.2529, Validation Loss: 5889.9519\n",
      "Epoch 2/3, Train Loss: 3878.2652, Validation Loss: 2541.0295\n",
      "Epoch 3/3, Train Loss: 2023.0695, Validation Loss: 1554.6458\n",
      "Fold 6, MAPE: 1.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7316.6597, Validation Loss: 5138.5900\n",
      "Epoch 2/3, Train Loss: 3318.0446, Validation Loss: 2216.7234\n",
      "Epoch 3/3, Train Loss: 1795.2054, Validation Loss: 1750.4905\n",
      "Fold 7, MAPE: 2969761310834688.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7013.1305, Validation Loss: 4681.2659\n",
      "Epoch 2/3, Train Loss: 2844.1360, Validation Loss: 1679.5333\n",
      "Epoch 3/3, Train Loss: 1704.3447, Validation Loss: 1330.9826\n",
      "Fold 8, MAPE: 3631652815241216.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6728.2444, Validation Loss: 4051.9021\n",
      "Epoch 2/3, Train Loss: 2452.7216, Validation Loss: 1627.5735\n",
      "Epoch 3/3, Train Loss: 1643.9173, Validation Loss: 1485.1392\n",
      "Fold 9, MAPE: 1057512015003648.0000\n",
      "Tested params: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.001}, Avg MAPE: 1247436475465728.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8943.5962, Validation Loss: 9733.4355\n",
      "Epoch 2/3, Train Loss: 8746.9519, Validation Loss: 9522.5200\n",
      "Epoch 3/3, Train Loss: 8548.3499, Validation Loss: 9293.7567\n",
      "Fold 0, MAPE: 0.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9281.3065, Validation Loss: 8232.2252\n",
      "Epoch 2/3, Train Loss: 8833.7851, Validation Loss: 7783.3413\n",
      "Epoch 3/3, Train Loss: 8330.6426, Validation Loss: 7285.9550\n",
      "Fold 1, MAPE: 1089569919336448.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8811.5769, Validation Loss: 8510.5522\n",
      "Epoch 2/3, Train Loss: 8131.5543, Validation Loss: 7754.6034\n",
      "Epoch 3/3, Train Loss: 7345.8110, Validation Loss: 6912.1651\n",
      "Fold 2, MAPE: 86342725795840.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8665.5282, Validation Loss: 8633.0980\n",
      "Epoch 2/3, Train Loss: 7700.1245, Validation Loss: 7542.1914\n",
      "Epoch 3/3, Train Loss: 6604.4520, Validation Loss: 6357.7823\n",
      "Fold 3, MAPE: 246221214056448.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8697.3122, Validation Loss: 8587.3514\n",
      "Epoch 2/3, Train Loss: 7423.9393, Validation Loss: 7130.7502\n",
      "Epoch 3/3, Train Loss: 5991.4696, Validation Loss: 5603.5705\n",
      "Fold 4, MAPE: 163910984400896.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8663.8099, Validation Loss: 7044.0952\n",
      "Epoch 2/3, Train Loss: 7063.9621, Validation Loss: 5507.7747\n",
      "Epoch 3/3, Train Loss: 5346.9574, Validation Loss: 4060.8740\n",
      "Fold 5, MAPE: 619393675427840.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8388.7734, Validation Loss: 7936.2393\n",
      "Epoch 2/3, Train Loss: 6501.1591, Validation Loss: 5791.6704\n",
      "Epoch 3/3, Train Loss: 4566.3537, Validation Loss: 3865.9540\n",
      "Fold 6, MAPE: 1.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8348.8093, Validation Loss: 7333.3165\n",
      "Epoch 2/3, Train Loss: 6105.4360, Validation Loss: 5025.4647\n",
      "Epoch 3/3, Train Loss: 3980.5819, Validation Loss: 3207.0745\n",
      "Fold 7, MAPE: 1749967647539200.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8165.2654, Validation Loss: 7310.7502\n",
      "Epoch 2/3, Train Loss: 5646.4053, Validation Loss: 4588.8691\n",
      "Epoch 3/3, Train Loss: 3443.8191, Validation Loss: 2627.0714\n",
      "Fold 8, MAPE: 2362547692896256.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8136.4943, Validation Loss: 6963.9224\n",
      "Epoch 2/3, Train Loss: 5319.1003, Validation Loss: 4085.9931\n",
      "Epoch 3/3, Train Loss: 3024.7549, Validation Loss: 2282.4921\n",
      "Fold 9, MAPE: 749473470873600.0000\n",
      "Tested params: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.1, 'lr': 0.0005}, Avg MAPE: 706742707027968.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8858.0460, Validation Loss: 9539.9580\n",
      "Epoch 2/3, Train Loss: 8474.5065, Validation Loss: 9089.0525\n",
      "Epoch 3/3, Train Loss: 8043.1275, Validation Loss: 8584.6420\n",
      "Fold 0, MAPE: 0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9128.8936, Validation Loss: 7862.5696\n",
      "Epoch 2/3, Train Loss: 8168.8554, Validation Loss: 6874.0606\n",
      "Epoch 3/3, Train Loss: 7059.7476, Validation Loss: 5791.4566\n",
      "Fold 1, MAPE: 2369500976513024.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8495.2006, Validation Loss: 7792.7816\n",
      "Epoch 2/3, Train Loss: 6986.9359, Validation Loss: 6103.2478\n",
      "Epoch 3/3, Train Loss: 5331.6468, Validation Loss: 4430.7883\n",
      "Fold 2, MAPE: 202126680653824.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8261.0738, Validation Loss: 7638.6891\n",
      "Epoch 2/3, Train Loss: 6147.7714, Validation Loss: 5294.2449\n",
      "Epoch 3/3, Train Loss: 4054.5096, Validation Loss: 3327.5057\n",
      "Fold 3, MAPE: 572197152227328.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8128.5193, Validation Loss: 7232.5952\n",
      "Epoch 2/3, Train Loss: 5407.0618, Validation Loss: 4308.7104\n",
      "Epoch 3/3, Train Loss: 3098.2438, Validation Loss: 2398.5855\n",
      "Fold 4, MAPE: 367327715524608.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7883.3719, Validation Loss: 5523.3836\n",
      "Epoch 2/3, Train Loss: 4584.7154, Validation Loss: 2931.2951\n",
      "Epoch 3/3, Train Loss: 2379.3886, Validation Loss: 1993.5931\n",
      "Fold 5, MAPE: 1309716990918656.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7520.0700, Validation Loss: 5896.9304\n",
      "Epoch 2/3, Train Loss: 3907.5116, Validation Loss: 2573.3507\n",
      "Epoch 3/3, Train Loss: 2045.4351, Validation Loss: 1558.5895\n",
      "Fold 6, MAPE: 1.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7323.6383, Validation Loss: 5180.5245\n",
      "Epoch 2/3, Train Loss: 3368.1179, Validation Loss: 2248.2758\n",
      "Epoch 3/3, Train Loss: 1816.6555, Validation Loss: 1754.0916\n",
      "Fold 7, MAPE: 2953656257216512.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 7038.1695, Validation Loss: 4687.4653\n",
      "Epoch 2/3, Train Loss: 2857.7678, Validation Loss: 1690.4804\n",
      "Epoch 3/3, Train Loss: 1714.5905, Validation Loss: 1333.0350\n",
      "Fold 8, MAPE: 3625392631971840.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 6778.9952, Validation Loss: 4127.5558\n",
      "Epoch 2/3, Train Loss: 2496.1464, Validation Loss: 1638.7177\n",
      "Epoch 3/3, Train Loss: 1650.9324, Validation Loss: 1486.7560\n",
      "Fold 9, MAPE: 1054180059906048.0000\n",
      "Tested params: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.001}, Avg MAPE: 1245409921990656.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8926.2858, Validation Loss: 9692.3349\n",
      "Epoch 2/3, Train Loss: 8713.6165, Validation Loss: 9475.3341\n",
      "Epoch 3/3, Train Loss: 8506.5379, Validation Loss: 9242.0493\n",
      "Fold 0, MAPE: 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 9313.1215, Validation Loss: 8246.9389\n",
      "Epoch 2/3, Train Loss: 8855.0649, Validation Loss: 7796.7050\n",
      "Epoch 3/3, Train Loss: 8351.7054, Validation Loss: 7301.1748\n",
      "Fold 1, MAPE: 1074131055411200.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8815.7858, Validation Loss: 8502.8739\n",
      "Epoch 2/3, Train Loss: 8118.8948, Validation Loss: 7735.7652\n",
      "Epoch 3/3, Train Loss: 7331.4636, Validation Loss: 6890.9298\n",
      "Fold 2, MAPE: 87210208526336.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8659.8394, Validation Loss: 8604.8014\n",
      "Epoch 2/3, Train Loss: 7658.6108, Validation Loss: 7469.5670\n",
      "Epoch 3/3, Train Loss: 6526.0011, Validation Loss: 6268.3076\n",
      "Fold 3, MAPE: 254022569164800.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8695.3786, Validation Loss: 8567.0742\n",
      "Epoch 2/3, Train Loss: 7397.2182, Validation Loss: 7091.1924\n",
      "Epoch 3/3, Train Loss: 5966.1828, Validation Loss: 5571.6677\n",
      "Fold 4, MAPE: 165413434425344.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8634.3118, Validation Loss: 6995.9080\n",
      "Epoch 2/3, Train Loss: 7010.2338, Validation Loss: 5449.9109\n",
      "Epoch 3/3, Train Loss: 5265.6148, Validation Loss: 3990.5011\n",
      "Fold 5, MAPE: 633198371405824.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8414.8267, Validation Loss: 7945.3051\n",
      "Epoch 2/3, Train Loss: 6503.5559, Validation Loss: 5792.0248\n",
      "Epoch 3/3, Train Loss: 4572.0458, Validation Loss: 3864.8531\n",
      "Fold 6, MAPE: 1.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8337.6719, Validation Loss: 7324.9349\n",
      "Epoch 2/3, Train Loss: 6112.9976, Validation Loss: 5033.7116\n",
      "Epoch 3/3, Train Loss: 3993.8931, Validation Loss: 3214.0471\n",
      "Fold 7, MAPE: 1745514437541888.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8218.2157, Validation Loss: 7401.3272\n",
      "Epoch 2/3, Train Loss: 5756.0743, Validation Loss: 4708.5633\n",
      "Epoch 3/3, Train Loss: 3542.1333, Validation Loss: 2709.6223\n",
      "Fold 8, MAPE: 2315973335973888.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 8091.6374, Validation Loss: 6908.7610\n",
      "Epoch 2/3, Train Loss: 5263.3981, Validation Loss: 4036.2252\n",
      "Epoch 3/3, Train Loss: 3002.1794, Validation Loss: 2270.0836\n",
      "Fold 9, MAPE: 752100514463744.0000\n",
      "Tested params: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.2, 'lr': 0.0005}, Avg MAPE: 702756373397504.0000\n",
      "Epoch 1/3, Train Loss: 8841.2256, Validation Loss: 9530.9399\n",
      "Epoch 2/3, Train Loss: 8466.1300, Validation Loss: 9090.3741\n",
      "Epoch 3/3, Train Loss: 8044.3406, Validation Loss: 8594.6929\n",
      "Fold 0, MAPE: 0.9027\n",
      "Epoch 1/3, Train Loss: 9099.1333, Validation Loss: 7846.0763\n",
      "Epoch 2/3, Train Loss: 8156.3370, Validation Loss: 6869.1056\n",
      "Epoch 3/3, Train Loss: 7056.4304, Validation Loss: 5796.1448\n",
      "Fold 1, MAPE: 2365392034988032.0000\n",
      "Epoch 1/3, Train Loss: 8526.3799, Validation Loss: 7851.1828\n",
      "Epoch 2/3, Train Loss: 7052.0531, Validation Loss: 6182.4034\n",
      "Epoch 3/3, Train Loss: 5398.9636, Validation Loss: 4506.9676\n",
      "Fold 2, MAPE: 197979084423168.0000\n",
      "Epoch 1/3, Train Loss: 8227.0983, Validation Loss: 7612.4969\n",
      "Epoch 2/3, Train Loss: 6111.5998, Validation Loss: 5246.7818\n",
      "Epoch 3/3, Train Loss: 4003.1839, Validation Loss: 3283.2973\n",
      "Fold 3, MAPE: 578523102183424.0000\n",
      "Epoch 1/3, Train Loss: 8088.5781, Validation Loss: 7208.5105\n",
      "Epoch 2/3, Train Loss: 5402.1952, Validation Loss: 4324.2910\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Device\u001b[39;00m\n\u001b[1;32m     38\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 40\u001b[0m grid_search_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrice1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_search_results)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Run cross-validation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m, in \u001b[0;36mgrid_search_lstm\u001b[0;34m(data, target_col, past_horizon, forecast_horizon, n_splits, param_grid, training_params, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m training_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m param_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Run cross-validation\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Compute average MAPE across folds\u001b[39;00m\n\u001b[1;32m     35\u001b[0m avg_mape \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAPE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mcross_validation_lstm\u001b[0;34m(data, target_col, past_horizon, forecast_horizon, n_splits, model_params, training_params, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mLSTM_multivariate_input_multi_step_forecaster(\n\u001b[1;32m     33\u001b[0m     input_size\u001b[38;5;241m=\u001b[39mmodel_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     34\u001b[0m     hidden_size\u001b[38;5;241m=\u001b[39mmodel_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     forecast_horizon\u001b[38;5;241m=\u001b[39mforecast_horizon\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, epochs, lr, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y_batch)\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/deep_learning_ex_2/lib/python3.12/site-packages/torch/optim/adam.py:394\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    393\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 394\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    397\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data preprocessing\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = dp.create_dataframe()\n",
    "\n",
    "# input_data = data.drop(columns=[\"DA\"]).values  # Extract features\n",
    "# target_data = data[\"DA\"].values.reshape(-1, 1)  # Extract target\n",
    "\n",
    "# scaled_input = scaler.fit_transform(input_data)\n",
    "# scaled_target = scaler.fit_transform(target_data)\n",
    "\n",
    "\n",
    "# Model and training parameters\n",
    "model_params = {\n",
    "    \"input_size\": 12,  # Number of features\n",
    "    \"hidden_size\": 100,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.2\n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_size\": [32, 64, 128],\n",
    "    \"num_layers\": [1, 2, 3],\n",
    "    \"dropout\": [0.1, 0.2],\n",
    "    \"lr\": [0.001, 0.0005]\n",
    "}\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "grid_search_results = grid_search_lstm(\n",
    "    data=data,\n",
    "    target_col=\"Price1\",\n",
    "    past_horizon=24,\n",
    "    forecast_horizon=24,\n",
    "    n_splits=10,\n",
    "    param_grid=param_grid,\n",
    "    training_params=training_params,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(grid_search_results)\n",
    "\n",
    "\n",
    "# Run cross-validation\n",
    "cv_results = cross_validation_lstm(\n",
    "    data=data,\n",
    "    target_col=\"Price1\",\n",
    "    past_horizon=24,\n",
    "    forecast_horizon=24,\n",
    "    n_splits=10,\n",
    "    model_params=model_params,\n",
    "    training_params=training_params,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_ex_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
