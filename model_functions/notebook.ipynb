{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_train_and_val' from 'lstm_functions' (c:\\Users\\storr\\OneDrive - Danmarks Tekniske Universitet\\Year 2\\Semester 1\\Deep Learning\\Project\\deeplearning\\model_functions\\lstm_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_prep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset,create_datasets, encode_time\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM_multivariate_input_multi_step_forecaster\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlstm_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_train_and_val\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'run_train_and_val' from 'lstm_functions' (c:\\Users\\storr\\OneDrive - Danmarks Tekniske Universitet\\Year 2\\Semester 1\\Deep Learning\\Project\\deeplearning\\model_functions\\lstm_functions.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import math as m\n",
    "#from typing import List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "from data_prep import Dataset,create_datasets, encode_time\n",
    "from model import LSTM_multivariate_input_multi_step_forecaster\n",
    "from lstm_functions import train_and_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_da_23 = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/deeplearning/models_santi/data_santi/data_da_23.csv')\n",
    "data_id_23 = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/deeplearning/models_santi/data_santi/data_id_23.csv')\n",
    "data_da_24 = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/deeplearning/models_santi/data_santi/data_da_24.csv')\n",
    "data_id_24 = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/deeplearning/models_santi/data_santi/data_id_24.csv')\n",
    "load_23_24 = pd.read_csv(r'/content/drive/My Drive/Colab Notebooks/deeplearning/models_santi/data_santi/load_data_2023_2024.csv',sep=';')\n",
    "\n",
    "data_da = pd.concat([data_da_23,data_da_24],ignore_index=True)\n",
    "data_id = pd.concat([data_id_23,data_id_24],ignore_index=True)\n",
    "\n",
    "# retriving only prices and load from data (not date columns)\n",
    "da_prices = data_da['DA ES']\n",
    "id_prices = data_id.iloc[:,-3:]\n",
    "load_23_24 = load_23_24['value']\n",
    "\n",
    "# saving date features\n",
    "date_features = pd.DataFrame()\n",
    "for feature,max_value in zip(['Month','Day','Hour'],[12,31,24]):\n",
    "  data_sin_feature = data_da[feature].apply(lambda x: m.sin(x*2*m.pi/max_value))\n",
    "  data_cos_feature = data_da[feature].apply(lambda x: m.cos(x*2*m.pi/max_value))\n",
    "  date_features = pd.concat([date_features,data_sin_feature,data_cos_feature],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting datasets\n",
    "lag_in_days = 7\n",
    "forecast_horizon_in_hours = 24\n",
    "\n",
    "input_data = np.hstack([np.array(date_features),np.array(load_23_24).reshape(len(load_23_24),1),np.array(da_prices).reshape(len(da_prices),1),np.array(id_prices)])\n",
    "output_data_DA = np.array(da_prices).reshape(len(da_prices),1)\n",
    "output_data_ID = np.array(id_prices.iloc[:,-1]).reshape(len(id_prices),1)\n",
    "output_DA_diff_ID = output_data_DA - output_data_ID\n",
    "\n",
    "# Set transforms if wanted here\n",
    "\n",
    "# Train,val and test sets\n",
    "training_set_DA, val_set_DA, test_set_DA = create_datasets(input_data,output_data_DA,lag_in_days,forecast_horizon_in_hours,Dataset)\n",
    "training_set_ID, val_set_ID, test_set_ID = create_datasets(input_data,output_data_ID,lag_in_days,forecast_horizon_in_hours,Dataset)\n",
    "training_set_DA_diff_ID, val_set_DA_diff_ID, test_set_DA_diff_ID = create_datasets(input_data,output_DA_diff_ID,lag_in_days,forecast_horizon_in_hours,Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models\n",
    "\n",
    "# model inputs\n",
    "input_size = training_set_DA.inputs.shape[2]\n",
    "future_inputs_size = training_set_DA.future_inputs.shape[2]\n",
    "past_horizon = training_set_DA.inputs.shape[1]\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "forecast_horizon = training_set_DA.targets.shape[1]\n",
    "dropout = 0.2\n",
    "\n",
    "model_DA = LSTM_multivariate_input_multi_step_forecaster(input_size, hidden_size,num_layers,dropout,past_horizon,forecast_horizon,future_inputs_size)\n",
    "model_ID = LSTM_multivariate_input_multi_step_forecaster(input_size, hidden_size,num_layers,dropout,past_horizon,forecast_horizon,future_inputs_size)\n",
    "model_DA_diff_ID = LSTM_multivariate_input_multi_step_forecaster(input_size, hidden_size,num_layers,dropout,past_horizon,forecast_horizon,future_inputs_size)\n",
    "\n",
    "optimizer_DA = optim.Adam(model_DA.parameters(),lr=0.001) # add momentum?\n",
    "optimizer_ID = optim.Adam(model_ID.parameters(),lr=0.001)\n",
    "optimizer_DA_diff_ID = optim.Adam(model_DA_diff_ID.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LSTM\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# training DA model\n",
    "train_loader_DA = torch.utils.data.DataLoader(\n",
    "    training_set_DA,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "val_loader_DA = torch.utils.data.DataLoader(\n",
    "    val_set_DA,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model_DA = train_and_val(train_loader_DA,val_loader_DA,num_epochs,model_DA,optimizer_DA,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "forecasts_DA = []\n",
    "targets_DA = []\n",
    "model_DA.eval()\n",
    "for inputs,target,future_inputs in val_loader_DA:\n",
    "  inputs = inputs.float()\n",
    "  target = target.float()\n",
    "  future_inputs = future_inputs.float()\n",
    "  forecast = model_DA(inputs,future_inputs)\n",
    "  forecasts_DA.append(forecast.data)\n",
    "  targets_DA.append(target.data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
