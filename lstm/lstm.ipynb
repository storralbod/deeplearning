{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hours recorded in marginalpdbc_20230326.1.csv: 23\n",
      "Hours recorded in precios_pibcic_20231029.1.csv: 25\n",
      "Hours recorded in precios_pibcic_20230326.1.csv: 23\n",
      "Hours recorded in marginalpdbc_20231029.1.csv: 25\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = os.path.join(os.path.dirname(os.getcwd()), 'data_23')\n",
    "data_files_path = os.listdir(data_folder_path)\n",
    "\n",
    "data_da = pd.DataFrame()\n",
    "data_id = pd.DataFrame()\n",
    "corrupted_data = []\n",
    "\n",
    "for file_path in data_files_path:\n",
    "\n",
    "    data_file_path = os.path.join(data_folder_path,file_path)\n",
    "\n",
    "    try:\n",
    "        single_day_data = pd.read_csv(data_file_path, sep=';', skiprows=1, header=None, encoding = 'latin-1')\n",
    "        single_day_data = single_day_data.iloc[:-1,:-1] # filtering out last row and columns which are blank\n",
    "\n",
    "        if file_path.split('_')[0] == 'marginalpdbc':\n",
    "\n",
    "            single_day_data.columns = ['Year','Month','Day','Hour','DA PT','DA ES'] # changing column names\n",
    "            cols = list(range(4)) + [5] #selecting only dates and Spain data columns\n",
    "            \n",
    "\n",
    "            if len(single_day_data) == 24:\n",
    "                data_da = pd.concat([data_da,single_day_data.iloc[:,cols]])\n",
    "            elif len(single_day_data) > 24:\n",
    "                data_da = pd.concat([data_da,single_day_data.iloc[:-1,cols]])\n",
    "            elif len(single_day_data) < 24:\n",
    "                hour_to_add = single_day_data.iloc[-1].copy()\n",
    "                hour_to_add.iloc[4:] = np.nan\n",
    "                hour_to_add.iloc[3] = 24\n",
    "                single_day_data_corrected = pd.concat([single_day_data,hour_to_add.to_frame().T])\n",
    "                data_da = pd.concat([data_da,single_day_data_corrected.iloc[:,cols]])\n",
    "\n",
    "        else:\n",
    "            single_day_data.columns = ['Year','Month','Day','Hour','MaxES','MaxPT','MaxMO','MinES','MinPT','MinMO','AvgES','AvgPT','AvgMO']\n",
    "            single_day_data = single_day_data.iloc[1:] # removing first row which are old headers not values\n",
    "            cols = list(range(5)) + [7, 10] #selecting only dates and Spain data columns\n",
    "\n",
    "            if len(single_day_data) == 24:\n",
    "                data_id = pd.concat([data_id,single_day_data.iloc[:,cols]])\n",
    "            elif len(single_day_data) > 24:\n",
    "                data_id = pd.concat([data_id,single_day_data.iloc[:-1,cols]])\n",
    "            elif len(single_day_data) < 24:\n",
    "                # copying last hour data to missing hour 24\n",
    "                hour_to_add = single_day_data.iloc[-1].copy()\n",
    "                hour_to_add.iloc[4:] = np.nan\n",
    "                hour_to_add.iloc[3] = 24\n",
    "                single_day_data_corrected = pd.concat([single_day_data,hour_to_add.to_frame().T])\n",
    "                data_id = pd.concat([data_id,single_day_data_corrected.iloc[:,cols]])\n",
    "\n",
    "        if len(single_day_data) != 24:\n",
    "            print(f'Hours recorded in {file_path}:', len(single_day_data))\n",
    "            corrupted_data.append(single_day_data)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'Error in file {file_path}')\n",
    "\n",
    "\n",
    "# Intraday market dataset given with commas - changing to '.' float\n",
    "data_id.iloc[:,4:] = data_id.iloc[:,4:].replace(',','.',regex=True).astype(float)\n",
    "\n",
    "# Change dates to str for consistency with data_id\n",
    "data_da[['Year', 'Month', 'Day', 'Hour']] = data_da[['Year', 'Month', 'Day', 'Hour']].astype(int)\n",
    "data_da[['Year', 'Month', 'Day', 'Hour']] = data_da[['Year', 'Month', 'Day', 'Hour']].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_ex_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
