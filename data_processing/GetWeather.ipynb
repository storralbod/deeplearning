{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This one works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 21:19:57,158 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2024-12-09 21:19:57,158 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2024-12-09 21:19:57,159 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2024-12-09 21:19:57,160 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n",
      "2024-12-09 21:19:57,362 INFO Request ID is fb9af629-c0f9-4e2b-906b-84ca09aed785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month: 01...\n",
      "File temp_weather_data/2023/01/Madrid_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Barcelona_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Seville_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Valencia_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Castile-La Mancha (Wind)_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Aragon (Wind)_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Andalusia (Wind)_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Escatrón-Chiprana-Samper (Solar)_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Talasol Solar (Solar)_2023-01.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/01/Talayuela Solar (Solar)_2023-01.grib already exists. Skipping download.\n",
      "Processing month: 02...\n",
      "File temp_weather_data/2023/02/Madrid_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Barcelona_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Seville_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Valencia_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Castile-La Mancha (Wind)_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Aragon (Wind)_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Andalusia (Wind)_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Escatrón-Chiprana-Samper (Solar)_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Talasol Solar (Solar)_2023-02.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/02/Talayuela Solar (Solar)_2023-02.grib already exists. Skipping download.\n",
      "Processing month: 03...\n",
      "File temp_weather_data/2023/03/Madrid_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Barcelona_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Seville_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Valencia_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Castile-La Mancha (Wind)_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Aragon (Wind)_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Andalusia (Wind)_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Escatrón-Chiprana-Samper (Solar)_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Talasol Solar (Solar)_2023-03.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/03/Talayuela Solar (Solar)_2023-03.grib already exists. Skipping download.\n",
      "Processing month: 04...\n",
      "File temp_weather_data/2023/04/Madrid_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Barcelona_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Seville_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Valencia_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Castile-La Mancha (Wind)_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Aragon (Wind)_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Andalusia (Wind)_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Escatrón-Chiprana-Samper (Solar)_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Talasol Solar (Solar)_2023-04.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/04/Talayuela Solar (Solar)_2023-04.grib already exists. Skipping download.\n",
      "Processing month: 05...\n",
      "File temp_weather_data/2023/05/Madrid_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Barcelona_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Seville_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Valencia_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Castile-La Mancha (Wind)_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Aragon (Wind)_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Andalusia (Wind)_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Escatrón-Chiprana-Samper (Solar)_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Talasol Solar (Solar)_2023-05.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/05/Talayuela Solar (Solar)_2023-05.grib already exists. Skipping download.\n",
      "Processing month: 06...\n",
      "File temp_weather_data/2023/06/Madrid_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Barcelona_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Seville_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Valencia_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Castile-La Mancha (Wind)_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Aragon (Wind)_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Andalusia (Wind)_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Escatrón-Chiprana-Samper (Solar)_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Talasol Solar (Solar)_2023-06.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/06/Talayuela Solar (Solar)_2023-06.grib already exists. Skipping download.\n",
      "Processing month: 07...\n",
      "File temp_weather_data/2023/07/Madrid_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Barcelona_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Seville_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Valencia_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Castile-La Mancha (Wind)_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Aragon (Wind)_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Andalusia (Wind)_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Escatrón-Chiprana-Samper (Solar)_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Talasol Solar (Solar)_2023-07.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/07/Talayuela Solar (Solar)_2023-07.grib already exists. Skipping download.\n",
      "Processing month: 08...\n",
      "File temp_weather_data/2023/08/Madrid_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Barcelona_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Seville_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Valencia_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Castile-La Mancha (Wind)_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Aragon (Wind)_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Andalusia (Wind)_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Escatrón-Chiprana-Samper (Solar)_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Talasol Solar (Solar)_2023-08.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/08/Talayuela Solar (Solar)_2023-08.grib already exists. Skipping download.\n",
      "Processing month: 09...\n",
      "File temp_weather_data/2023/09/Madrid_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Barcelona_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Seville_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Valencia_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Castile-La Mancha (Wind)_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Aragon (Wind)_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Andalusia (Wind)_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Escatrón-Chiprana-Samper (Solar)_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Talasol Solar (Solar)_2023-09.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/09/Talayuela Solar (Solar)_2023-09.grib already exists. Skipping download.\n",
      "Processing month: 10...\n",
      "File temp_weather_data/2023/10/Madrid_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Barcelona_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Seville_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Valencia_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Castile-La Mancha (Wind)_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Aragon (Wind)_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Andalusia (Wind)_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Escatrón-Chiprana-Samper (Solar)_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Talasol Solar (Solar)_2023-10.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/10/Talayuela Solar (Solar)_2023-10.grib already exists. Skipping download.\n",
      "Processing month: 11...\n",
      "File temp_weather_data/2023/11/Madrid_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Barcelona_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Seville_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Valencia_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Castile-La Mancha (Wind)_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Aragon (Wind)_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Andalusia (Wind)_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Escatrón-Chiprana-Samper (Solar)_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Talasol Solar (Solar)_2023-11.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/11/Talayuela Solar (Solar)_2023-11.grib already exists. Skipping download.\n",
      "Processing month: 12...\n",
      "File temp_weather_data/2023/12/Madrid_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Barcelona_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Seville_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Valencia_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Castile-La Mancha (Wind)_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Aragon (Wind)_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Andalusia (Wind)_2023-12.grib already exists. Skipping download.\n",
      "File temp_weather_data/2023/12/Escatrón-Chiprana-Samper (Solar)_2023-12.grib already exists. Skipping download.\n",
      "Requesting data for Talasol Solar (Solar) (39.7291, -6.3391) for month 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 21:19:57,427 INFO status has been updated to accepted\n",
      "2024-12-09 21:20:03,043 INFO status has been updated to successful\n",
      "2024-12-09 21:20:03,903 INFO Request ID is 92bafa2f-0d83-4d30-944c-d6aba8ccc32e         \n",
      "2024-12-09 21:20:03,954 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to temp_weather_data/2023/12/Talasol Solar (Solar)_2023-12.grib.\n",
      "Requesting data for Talayuela Solar (Solar) (39.9862, -5.9815) for month 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 21:20:10,641 INFO status has been updated to running\n",
      "2024-12-09 21:24:25,302 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to temp_weather_data/2023/12/Talayuela Solar (Solar)_2023-12.grib.\n",
      "Processing month directory: temp_weather_data/2023/01...\n",
      "Processing file: temp_weather_data/2023/01/Valencia_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Barcelona_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Escatrón-Chiprana-Samper (Solar)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Aragon (Wind)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Castile-La Mancha (Wind)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Madrid_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Talayuela Solar (Solar)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Talasol Solar (Solar)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Andalusia (Wind)_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Seville_2023-01.grib...\n",
      "Processing file: temp_weather_data/2023/01/Bilbao_2023-01.grib...\n",
      "Processing month directory: temp_weather_data/2023/02...\n",
      "Processing file: temp_weather_data/2023/02/Madrid_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Barcelona_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Seville_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Valencia_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Escatrón-Chiprana-Samper (Solar)_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Andalusia (Wind)_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Castile-La Mancha (Wind)_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Talayuela Solar (Solar)_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Aragon (Wind)_2023-02.grib...\n",
      "Processing file: temp_weather_data/2023/02/Talasol Solar (Solar)_2023-02.grib...\n",
      "Processing month directory: temp_weather_data/2023/03...\n",
      "Processing file: temp_weather_data/2023/03/Talasol Solar (Solar)_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Escatrón-Chiprana-Samper (Solar)_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Aragon (Wind)_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Seville_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Castile-La Mancha (Wind)_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Andalusia (Wind)_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Barcelona_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Madrid_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Valencia_2023-03.grib...\n",
      "Processing file: temp_weather_data/2023/03/Talayuela Solar (Solar)_2023-03.grib...\n",
      "Processing month directory: temp_weather_data/2023/04...\n",
      "Processing file: temp_weather_data/2023/04/Talayuela Solar (Solar)_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Barcelona_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Madrid_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Andalusia (Wind)_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Seville_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Castile-La Mancha (Wind)_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Talasol Solar (Solar)_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Escatrón-Chiprana-Samper (Solar)_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Valencia_2023-04.grib...\n",
      "Processing file: temp_weather_data/2023/04/Aragon (Wind)_2023-04.grib...\n",
      "Processing month directory: temp_weather_data/2023/05...\n",
      "Processing file: temp_weather_data/2023/05/Madrid_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Valencia_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Escatrón-Chiprana-Samper (Solar)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Talasol Solar (Solar)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Castile-La Mancha (Wind)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Aragon (Wind)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Talayuela Solar (Solar)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Seville_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Andalusia (Wind)_2023-05.grib...\n",
      "Processing file: temp_weather_data/2023/05/Barcelona_2023-05.grib...\n",
      "Processing month directory: temp_weather_data/2023/06...\n",
      "Processing file: temp_weather_data/2023/06/Barcelona_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Andalusia (Wind)_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Valencia_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Talasol Solar (Solar)_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Castile-La Mancha (Wind)_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Aragon (Wind)_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Madrid_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Talayuela Solar (Solar)_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Seville_2023-06.grib...\n",
      "Processing file: temp_weather_data/2023/06/Escatrón-Chiprana-Samper (Solar)_2023-06.grib...\n",
      "Processing month directory: temp_weather_data/2023/07...\n",
      "Processing file: temp_weather_data/2023/07/Escatrón-Chiprana-Samper (Solar)_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Seville_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Talayuela Solar (Solar)_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Barcelona_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Andalusia (Wind)_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Valencia_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Madrid_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Talasol Solar (Solar)_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Aragon (Wind)_2023-07.grib...\n",
      "Processing file: temp_weather_data/2023/07/Castile-La Mancha (Wind)_2023-07.grib...\n",
      "Processing month directory: temp_weather_data/2023/08...\n",
      "Processing file: temp_weather_data/2023/08/Barcelona_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Aragon (Wind)_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Valencia_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Castile-La Mancha (Wind)_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Madrid_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Talasol Solar (Solar)_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Talayuela Solar (Solar)_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Escatrón-Chiprana-Samper (Solar)_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Seville_2023-08.grib...\n",
      "Processing file: temp_weather_data/2023/08/Andalusia (Wind)_2023-08.grib...\n",
      "Processing month directory: temp_weather_data/2023/09...\n",
      "Processing file: temp_weather_data/2023/09/Talayuela Solar (Solar)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Andalusia (Wind)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Aragon (Wind)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Escatrón-Chiprana-Samper (Solar)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Seville_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Barcelona_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Madrid_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Castile-La Mancha (Wind)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Talasol Solar (Solar)_2023-09.grib...\n",
      "Processing file: temp_weather_data/2023/09/Valencia_2023-09.grib...\n",
      "Processing month directory: temp_weather_data/2023/10...\n",
      "Processing file: temp_weather_data/2023/10/Escatrón-Chiprana-Samper (Solar)_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Madrid_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Talayuela Solar (Solar)_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Valencia_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Aragon (Wind)_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Seville_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Andalusia (Wind)_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Castile-La Mancha (Wind)_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Barcelona_2023-10.grib...\n",
      "Processing file: temp_weather_data/2023/10/Talasol Solar (Solar)_2023-10.grib...\n",
      "Processing month directory: temp_weather_data/2023/11...\n",
      "Processing file: temp_weather_data/2023/11/Talasol Solar (Solar)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Barcelona_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Escatrón-Chiprana-Samper (Solar)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Aragon (Wind)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Castile-La Mancha (Wind)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Seville_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Talayuela Solar (Solar)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Andalusia (Wind)_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Valencia_2023-11.grib...\n",
      "Processing file: temp_weather_data/2023/11/Madrid_2023-11.grib...\n",
      "Processing month directory: temp_weather_data/2023/12...\n",
      "Processing file: temp_weather_data/2023/12/Valencia_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Castile-La Mancha (Wind)_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Seville_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Andalusia (Wind)_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Talasol Solar (Solar)_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Escatrón-Chiprana-Samper (Solar)_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Madrid_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Aragon (Wind)_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Barcelona_2023-12.grib...\n",
      "Processing file: temp_weather_data/2023/12/Talayuela Solar (Solar)_2023-12.grib...\n",
      "Combining all data into a single DataFrame...\n",
      "Consolidated weather data saved to output_weather_data/weather_data_2023.csv.\n"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "import xarray as xr\n",
    "\n",
    "# Load the configuration\n",
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "locations = config[\"locations\"]\n",
    "variables = config[\"variables\"]\n",
    "times = config[\"time\"]  # Get the timeslots from the configuration file\n",
    "\n",
    "# Define the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Base directories for temporary and output files\n",
    "base_temp_dir = \"temp_weather_data\"\n",
    "base_output_dir = \"output_weather_data\"\n",
    "os.makedirs(base_temp_dir, exist_ok=True)\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "# Generate data for each month\n",
    "for month in range(1, 13):  # Loop through months 1 to 12\n",
    "    month_str = f\"{month:02}\"  # Ensure two-digit month format\n",
    "\n",
    "    # Determine the number of days in the current month\n",
    "    num_days = monthrange(2023, month)[1]\n",
    "    days = [f\"{day:02}\" for day in range(1, num_days + 1)]\n",
    "\n",
    "    print(f\"Processing month: {month_str}...\")\n",
    "\n",
    "    # Create a directory for this month\n",
    "    temp_dir = os.path.join(base_temp_dir, \"2023\", month_str)\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Process each location\n",
    "    for location in locations:\n",
    "        lat, lon, name = location[\"latitude\"], location[\"longitude\"], location[\"name\"]\n",
    "        file_name = os.path.join(temp_dir, f\"{name}_2023-{month_str}.grib\")\n",
    "        \n",
    "        if not os.path.exists(file_name):  # Avoid re-downloading if file exists\n",
    "            print(f\"Requesting data for {name} ({lat}, {lon}) for month {month_str}...\")\n",
    "            request = {\n",
    "                \"variable\": variables,\n",
    "                \"year\": \"2023\",\n",
    "                \"month\": [month_str],\n",
    "                \"day\": days,  # Dynamically calculated days\n",
    "                \"time\": times,  # Time slots from configuration\n",
    "                \"format\": \"grib\",\n",
    "                \"area\": [lat + 0.1, lon - 0.1, lat - 0.1, lon + 0.1],\n",
    "            }\n",
    "            try:\n",
    "                c.retrieve(\"reanalysis-era5-land\", request, file_name)\n",
    "                print(f\"Data saved to {file_name}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving data for {name}, {month_str}: {e}\")\n",
    "        else:\n",
    "            print(f\"File {file_name} already exists. Skipping download.\")\n",
    "\n",
    "# Consolidate all downloaded data\n",
    "all_data = []\n",
    "\n",
    "# Process each month directory\n",
    "year_dir = os.path.join(base_temp_dir, \"2023\")\n",
    "for month_dir in sorted(os.listdir(year_dir)):\n",
    "    month_path = os.path.join(year_dir, month_dir)\n",
    "    if os.path.isdir(month_path):\n",
    "        print(f\"Processing month directory: {month_path}...\")\n",
    "        for file in os.listdir(month_path):\n",
    "            if file.endswith(\".grib\"):\n",
    "                file_path = os.path.join(month_path, file)\n",
    "                print(f\"Processing file: {file_path}...\")\n",
    "                try:\n",
    "                    ds = xr.open_dataset(file_path, engine=\"cfgrib\")\n",
    "                    df = ds.to_dataframe().reset_index()\n",
    "\n",
    "                    # Extract location name from file\n",
    "                    location_name = file.split(\"_2023-\")[0]\n",
    "\n",
    "                    # Add metadata\n",
    "                    df[\"location_name\"] = location_name\n",
    "\n",
    "                    all_data.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "if all_data:\n",
    "    print(\"Combining all data into a single DataFrame...\")\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Save combined data to CSV\n",
    "    output_csv_file = os.path.join(base_output_dir, \"weather_data_2023.csv\")\n",
    "    combined_df.to_csv(output_csv_file, index=False)\n",
    "    print(f\"Consolidated weather data saved to {output_csv_file}.\")\n",
    "else:\n",
    "    print(\"No data to consolidate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading output_weather_data/weather_data_2023.csv...\n",
      "Processing data...\n",
      "Saving data by location to output_weather_data/weather_data_by_location_2023.json...\n",
      "Consolidating data by time...\n",
      "Saving consolidated data to output_weather_data/consolidated_weather_data_by_time_2023.csv...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "input_csv = \"output_weather_data/weather_data_2023.csv\"\n",
    "output_json = \"output_weather_data/weather_data_by_location_2023.json\"\n",
    "output_csv = \"output_weather_data/consolidated_weather_data_by_time_2023.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "print(f\"Loading {input_csv}...\")\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Convert time columns to datetime for easier processing\n",
    "df[\"valid_time\"] = pd.to_datetime(df[\"valid_time\"])\n",
    "\n",
    "# Initialize the main dictionary\n",
    "weather_data = {}\n",
    "\n",
    "# Group the data by location and valid_time\n",
    "print(\"Processing data...\")\n",
    "grouped = df.groupby([\"location_name\", \"valid_time\"])\n",
    "\n",
    "for (location, valid_time), group in grouped:\n",
    "    # Initialize the location's data if not already present\n",
    "    if location not in weather_data:\n",
    "        weather_data[location] = []\n",
    "\n",
    "    # Aggregate data for the time slot\n",
    "    aggregated_data = {\n",
    "        \"valid_time\": valid_time.isoformat(),\n",
    "        \"latitude\": group[\"latitude\"].mean(skipna=True),\n",
    "        \"longitude\": group[\"longitude\"].mean(skipna=True),\n",
    "        \"temperature\": group[\"t2m\"].mean(skipna=True),\n",
    "        \"solar_radiation\": group[\"ssr\"].mean(skipna=True),\n",
    "        \"wind_u_component\": group[\"u10\"].mean(skipna=True),\n",
    "        \"wind_v_component\": group[\"v10\"].mean(skipna=True),\n",
    "        \"surface_pressure\": group[\"sp\"].mean(skipna=True),\n",
    "        \"total_precipitation\": group[\"tp\"].mean(skipna=True),\n",
    "    }\n",
    "    weather_data[location].append(aggregated_data)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "print(f\"Saving data by location to {output_json}...\")\n",
    "with open(output_json, \"w\") as json_file:\n",
    "    json.dump(weather_data, json_file, indent=4)\n",
    "\n",
    "# Consolidate data by valid_time\n",
    "print(\"Consolidating data by time...\")\n",
    "consolidated_data = {}\n",
    "\n",
    "# Process each location\n",
    "for location, records in weather_data.items():\n",
    "    for record in records:\n",
    "        valid_time = record[\"valid_time\"]\n",
    "\n",
    "        # Ensure the valid_time exists in the consolidated data\n",
    "        if valid_time not in consolidated_data:\n",
    "            consolidated_data[valid_time] = {}\n",
    "\n",
    "        # Flatten location-specific data into consolidated_data\n",
    "        consolidated_data[valid_time].update({\n",
    "            f\"{location}_latitude\": record[\"latitude\"],\n",
    "            f\"{location}_longitude\": record[\"longitude\"],\n",
    "            f\"{location}_temperature\": record[\"temperature\"],\n",
    "            f\"{location}_solar_radiation\": record[\"solar_radiation\"],\n",
    "            f\"{location}_wind_u_component\": record[\"wind_u_component\"],\n",
    "            f\"{location}_wind_v_component\": record[\"wind_v_component\"],\n",
    "            f\"{location}_surface_pressure\": record[\"surface_pressure\"],\n",
    "            f\"{location}_total_precipitation\": record[\"total_precipitation\"],\n",
    "        })\n",
    "\n",
    "# Convert the consolidated dictionary into a DataFrame\n",
    "df_consolidated = pd.DataFrame.from_dict(consolidated_data, orient=\"index\").reset_index()\n",
    "\n",
    "# Rename the index column to \"valid_time\"\n",
    "df_consolidated.rename(columns={\"index\": \"valid_time\"}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "print(f\"Saving consolidated data to {output_csv}...\")\n",
    "df_consolidated.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The current process is above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from output_weather_data/weather_data_2023.csv...\n",
      "Processing data...\n",
      "Saving processed data to temp/2023_weather_data_by_location.json...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'temp/2023_weather_data_by_location.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Save the processed data to a JSON file\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving processed data to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_json_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m     47\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(weather_data, json_file, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Consolidate the data by `valid_time` for the CSV output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearn/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'temp/2023_weather_data_by_location.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "year = 2023\n",
    "base_dir = \"temp\"\n",
    "\n",
    "# Initialize the main dictionary\n",
    "weather_data = {}\n",
    "\n",
    "# Iterate through all months\n",
    "for month in range(1, 13):\n",
    "    month_dir = os.path.join(base_dir, str(year), f\"{month:02d}\")\n",
    "    month_file = os.path.join(month_dir, \"weather_data.csv\")\n",
    "    \n",
    "    # Check if the month's file exists\n",
    "    if not os.path.exists(month_file):\n",
    "        print(f\"Skipping {month_file}: File not found.\")\n",
    "        continue\n",
    "\n",
    "    # Load the CSV file for the month\n",
    "    print(f\"Processing {month_file}...\")\n",
    "    df = pd.read_csv(month_file)\n",
    "\n",
    "    # Convert time columns to datetime for easier processing\n",
    "    df[\"valid_time\"] = pd.to_datetime(df[\"valid_time\"])\n",
    "\n",
    "    # Group the data by location\n",
    "    for location, group in df.groupby(\"location_name\"):\n",
    "        # Initialize the location's data if not already present\n",
    "        if location not in weather_data:\n",
    "            weather_data[location] = []\n",
    "\n",
    "        # Drop duplicate time slots by keeping the first non-NaN row for each `valid_time`\n",
    "        group = group.sort_values(\"valid_time\").dropna(subset=[\"t2m\", \"ssr\", \"u10\", \"v10\", \"sp\", \"tp\"], how='all')\n",
    "        group = group.groupby(\"valid_time\").first().reset_index()\n",
    "\n",
    "        # Process each row in the location's data\n",
    "        for _, row in group.iterrows():\n",
    "            # Create a dictionary for the current time slot\n",
    "            time_slot_data = {\n",
    "                \"valid_time\": row[\"valid_time\"].isoformat(),\n",
    "                \"latitude\": row[\"latitude\"],\n",
    "                \"longitude\": row[\"longitude\"],\n",
    "                \"temperature\": row[\"t2m\"],\n",
    "                \"solar_radiation\": row[\"ssr\"],\n",
    "                \"wind_u_component\": row[\"u10\"],\n",
    "                \"wind_v_component\": row[\"v10\"],\n",
    "                \"surface_pressure\": row[\"sp\"],\n",
    "                \"total_precipitation\": row[\"tp\"],\n",
    "            }\n",
    "            weather_data[location].append(time_slot_data)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "output_file = os.path.join(base_dir, f\"{year}_weather_data_by_location.json\")\n",
    "with open(output_file, \"w\") as json_file:\n",
    "    json.dump(weather_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Weather data organized by location saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated weather data by time saved to consolidated_weather_data_by_time.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "input_file = \"weather_data_by_location.json\"\n",
    "output_csv_file = \"consolidated_weather_data_by_time.csv\"\n",
    "\n",
    "with open(input_file, \"r\") as json_file:\n",
    "    weather_data = json.load(json_file)\n",
    "\n",
    "# Create a dictionary to hold data for the DataFrame\n",
    "consolidated_data = {}\n",
    "\n",
    "# Process each location\n",
    "for location, records in weather_data.items():\n",
    "    for record in records:\n",
    "        valid_time = record[\"valid_time\"]\n",
    "\n",
    "        # Ensure the valid_time exists in the consolidated data\n",
    "        if valid_time not in consolidated_data:\n",
    "            consolidated_data[valid_time] = {}\n",
    "\n",
    "        # Flatten location-specific data into consolidated_data\n",
    "        consolidated_data[valid_time].update({\n",
    "            f\"{location}_latitude\": record[\"latitude\"],\n",
    "            f\"{location}_longitude\": record[\"longitude\"],\n",
    "            f\"{location}_temperature\": record[\"temperature\"],\n",
    "            f\"{location}_solar_radiation\": record[\"solar_radiation\"],\n",
    "            f\"{location}_wind_u_component\": record[\"wind_u_component\"],\n",
    "            f\"{location}_wind_v_component\": record[\"wind_v_component\"],\n",
    "            f\"{location}_surface_pressure\": record[\"surface_pressure\"],\n",
    "            f\"{location}_total_precipitation\": record[\"total_precipitation\"],\n",
    "        })\n",
    "\n",
    "# Convert the consolidated dictionary into a DataFrame\n",
    "df = pd.DataFrame.from_dict(consolidated_data, orient=\"index\").reset_index()\n",
    "\n",
    "# Rename the index column to \"valid_time\"\n",
    "df.rename(columns={\"index\": \"valid_time\"}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Consolidated weather data by time saved to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation shit I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading output_weather_data/weather_data_2023.csv...\n",
      "Processing data...\n",
      "Saving data by location to output_weather_data/weather_data_by_location_2023.json...\n",
      "Consolidating data by time...\n",
      "Saving consolidated data to output_weather_data/consolidated_weather_data_by_time_2023.csv...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "input_csv = \"output_weather_data/weather_data_2023.csv\"\n",
    "output_json = \"output_weather_data/weather_data_by_location_2023.json\"\n",
    "output_csv = \"output_weather_data/consolidated_weather_data_by_time_2023.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "print(f\"Loading {input_csv}...\")\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Convert time columns to datetime for easier processing\n",
    "df[\"valid_time\"] = pd.to_datetime(df[\"valid_time\"])\n",
    "\n",
    "# Initialize the main dictionary\n",
    "weather_data = {}\n",
    "\n",
    "# Group the data by location and valid_time\n",
    "print(\"Processing data...\")\n",
    "grouped = df.groupby([\"location_name\", \"valid_time\"])\n",
    "\n",
    "for (location, valid_time), group in grouped:\n",
    "    # Initialize the location's data if not already present\n",
    "    if location not in weather_data:\n",
    "        weather_data[location] = []\n",
    "\n",
    "    # Aggregate data for the time slot\n",
    "    aggregated_data = {\n",
    "        \"valid_time\": valid_time.isoformat(),\n",
    "        \"latitude\": group[\"latitude\"].mean(skipna=True),\n",
    "        \"longitude\": group[\"longitude\"].mean(skipna=True),\n",
    "        \"temperature\": group[\"t2m\"].mean(skipna=True),\n",
    "        \"solar_radiation\": group[\"ssr\"].mean(skipna=True),\n",
    "        \"wind_u_component\": group[\"u10\"].mean(skipna=True),\n",
    "        \"wind_v_component\": group[\"v10\"].mean(skipna=True),\n",
    "        \"surface_pressure\": group[\"sp\"].mean(skipna=True),\n",
    "        \"total_precipitation\": group[\"tp\"].mean(skipna=True),\n",
    "    }\n",
    "    weather_data[location].append(aggregated_data)\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "print(f\"Saving data by location to {output_json}...\")\n",
    "with open(output_json, \"w\") as json_file:\n",
    "    json.dump(weather_data, json_file, indent=4)\n",
    "\n",
    "# Consolidate data by valid_time\n",
    "print(\"Consolidating data by time...\")\n",
    "consolidated_data = {}\n",
    "\n",
    "# Process each location\n",
    "for location, records in weather_data.items():\n",
    "    for record in records:\n",
    "        valid_time = record[\"valid_time\"]\n",
    "\n",
    "        # Ensure the valid_time exists in the consolidated data\n",
    "        if valid_time not in consolidated_data:\n",
    "            consolidated_data[valid_time] = {}\n",
    "\n",
    "        # Flatten location-specific data into consolidated_data\n",
    "        consolidated_data[valid_time].update({\n",
    "            f\"{location}_latitude\": record[\"latitude\"],\n",
    "            f\"{location}_longitude\": record[\"longitude\"],\n",
    "            f\"{location}_temperature\": record[\"temperature\"],\n",
    "            f\"{location}_solar_radiation\": record[\"solar_radiation\"],\n",
    "            f\"{location}_wind_u_component\": record[\"wind_u_component\"],\n",
    "            f\"{location}_wind_v_component\": record[\"wind_v_component\"],\n",
    "            f\"{location}_surface_pressure\": record[\"surface_pressure\"],\n",
    "            f\"{location}_total_precipitation\": record[\"total_precipitation\"],\n",
    "        })\n",
    "\n",
    "# Convert the consolidated dictionary into a DataFrame\n",
    "df_consolidated = pd.DataFrame.from_dict(consolidated_data, orient=\"index\").reset_index()\n",
    "\n",
    "# Rename the index column to \"valid_time\"\n",
    "df_consolidated.rename(columns={\"index\": \"valid_time\"}, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "print(f\"Saving consolidated data to {output_csv}...\")\n",
    "df_consolidated.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
